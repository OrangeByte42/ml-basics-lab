# 基本术语

- 数据集（dataset）；
    - 训练数据集（training dataset）/ 训练集（training set）：
        - 用于拟合模型参数的数据集；
        - 用于通过最小化总损失来学习模型参数的最佳值的数据集，该数据集由一些为训练而收集的样本组成；

    - 测试数据集（test dataset）/ 测试集（test set）：
        - 用于评估拟合的模型的数据集；
        - 在训练数据集上表现良好的模型，并不一定在“新数据集”上有同样的性能。此处“新数据集”通常称为 测试数据集；

- 参数（parameter）；
- 模型（model）：任一调整参数后获得“最佳参数集”的程序；
- 模型族：通过操作参数而生成的所有不同程序（输入-输出映射）的集合；
- 学习算法（Learning Algorithm）：使用数据集来选择参数的元程序；
- 学习（learning）：训练模型的过程，通过该过程可以发现正确的参数集，从而使得模型强制执行所需的行为。即使用数据训练模型；
    - 这里所说的“学习”，是指自主提高模型完成某些任务的效能；
- 训练（train）；
    - 训练通常包括下述步骤：
        1. 从一个随机初始化参数的模型开始，这个模型基本没有“智能”；
        2. 获取一些数据样本；
        3. 调整参数，使模型在这些样本中表现得很好；
        4. 重复步骤2、3，直到模型在任务中表现得令人满意；
- 数据编程（programming with data）：通过用数据集来确定程序行为；
- 深度学习（Deep Learning）；
    - 深度学习是机器学习的一个主要分支；
- 过拟合（overfitting）：当一个模型在训练集上表现良好，但不能推广到测试集的情况；

- 样本（sample）/数据点（data point）/ 数据样本（data instance）
- 标签（label）/ 目标（target）
- 特征（feature）/协变量（covariate）

## 机器学习中的关键组件

首先介绍一些核心组件。无论什么类型的机器学习问题，都会遇到这些组件：
1. 可用来学习的数据（data）；
2. 如何转换数据的模型（model）；
3. 一个目标函数（objective function），用来量化模型的有效性；
4. 调整模型参数以优化目标函数的算法（algorithm）；

### 数据

- 样本（example, sample）：每个数据集由一个个样本组成；
    - 样本也被称作 数据点（data point）或 数据实例（data instance）；
    - 通常每个样本由一组成为特征（features，或协变量（covariates））的属性组成；
    - 数据的 维数（dimensionality）：
        - 当每个样本的特征类别数量都是相同的时候，其特征向量是固定长度的，这个长度被称为数据的维数；
        - 固定长度的特征向量是一个方便的属性，它可以用来量化学习大量样本；
        - 然而，并不是所有的数据都可以用“固定长度”的向量表示；
- 独立同分布（independently and identically distributed, i.i.d）：大多时候，样本遵循独立同分布；
- 标签（label）：也被称为 目标（target）；

与传统机器学习方法相比,深度学习的一个主要优势是可以处理不同⻓度的数据。

一般来说,拥有越多数据的时候,工作就越容易。更多的数据可以被用来训练出更强大的模型,从而减少对  预先设想假设的依赖。数据集的由小变大为现代深度学习的成功奠定基础。在没有大数据集的情况下,许多  令人兴奋的深度学习模型黯然失色。就算一些深度学习模型在小数据集上能够工作,但其效能并不比传统方  法高。

请注意,仅仅拥有海量的数据是不够的,我们还需要正确的数据。如果数据中充满了错误,或者如果数据的  特征不能预测任务目标,那么模型很可能无效。有一句古语很好地反映了这个现象:“输入的是垃圾,输出的  也是垃圾。”(“Garbage in, garbage out.”)此外,糟糕的预测性能甚至会加倍放大事态的严重性。

当数据不具有充  分代表性,甚至包含了一些社会偏⻅时,模型就很有可能有偏⻅。

大多数机器学习会涉及到数据的转换。

### 模型

深度学习与经典方法的区别主要在于:前者关注的功能强大的模型,这些模型由神经  网络错综复杂的交织在一起,包含层层数据转换,因此被称为深度学习(deep learning)。

### 目标函数

- 目标函数（objective function）：对模型优劣程度的度量，在大多数情况是“可优化”的；
    - 通常定义一个目标函数，并希望优化它到最低点；
    - 这个函数有时被称为 损失函数（loss function / cost function）；
    - 试图预测数值时，最常见的损失函数是 平方误差（squared error）：即预测值与实际值之差的平方；
    - 解决分类问题时，最常见的目标函数是 最小化错误率：即预测与实际情况不符的样本比例；
    - 有些目标（如平方误差）很容易被优化，有些目标（如错误率）由于不可微性或其它复杂性难以直接优化。在这些情况下，通常会优化替代目标；
    - 通常，损失函数是根据模型参数定义的，并取决于数据集；

### 优化算法

当 获得数据源及其表示、模型 和 合适的损失函数，接下来就需要一种算法，其能够搜索出最佳参数，以最小化损失函数；

- 梯度下降（gradient descent）：
    - 大多流行的优化算法通常基于该基本优化方法；
    - 在每个步骤中，梯度下降法都会检查每个参数，看看如果仅对该参数进行少量变动，训练集损失会朝哪个方向移动，然后在减少损失的方向上优化参数；



## 机器学习问题分类

- 监督学习（supervised learning）：
    - 擅长在 “给定输入特征” 的情况下预测标签。每个 “特征-标签” 对都称为一个样本（example）。有时即使标签未知，样本也可以指代输入特征；
    - 目标是生成一个模型，能够将任何输入特征映射到标签（即预测“估计给定输入特征的标签”的条件概率）；
    - 虽然监督学习只是几大类机器学习问题之一，但在工业中，大部分机器学习的成功应用都使用了监督学习。因为在一定程度上，许多重要的任务都可清晰地描述为：在给定一组特定的可用数据的情况下，估计未知事物的概率；
    - 学习过程一般分为三大步骤：
        1. 从已知大量数据样本中随机选取一个子集，为每个样本获取真实标签。有时，这些样本已有标签；有时，这些样本可能需要人工标记标签。这些输入和相应的标签一起构成了训练数据集；
        2. 选择有监督的学习算法，它将训练数据集作为输入，并输出一个“已完成学习的模型”；
        3. 将之前没有见过的样本特征放到这个“已完成学习的模型”中，使用模型的输出作为相应标签的预测；
    - 监督学习任务分类：
        - 回归（regression）：
            - 最简单的监督学习任务之一。当标签取任意数值时，称之为回归问题，此时目标是生成一个模型，使它的预测非常接近实际标签值；
            - 生活中的许多问题都可归类为回归问题。总而言之，判断回归问题的一个很好的经验法则是，任何有关“有多少”的问题很可能就是回归问题；
            - 回归是训练一个回归函数来输出一个数值；
        - 分类（classification）：判断属于“哪一个”的问题称之为分类问题；
            - 分类问题希望模型能够预测样本属于哪个类别（category，正式称为类（class））；
            - 最简单的分类问题是只有两类，这被称之为二项分类（binomial classification）；
            - 分类是训练一个分类器来输出预测的类别。对于“是”或“不是”这类硬分类预测，可使用概率语言来理解模型。预测类别的概率大小传达了一种模型的不确定性；
            - TODO：运用不确定性概念的算法；
            - 当有两个以上的类别时，将问题称为 多项分类（multiclass classification）问题；
            - 与解决回归问题不同，分类问题的常见损失函数被称为交叉熵（cross-entropy）；
            - 需要注意的是，最常见/概率最大的类别不一定是最终用于决策的类别；
            - 层次分类（hierarchical classification）：
                - 分类可能变得比二项分类、多项分类复杂得多。例如,有一些分类任务的变体可以用于寻找层次结构,层次  结构假定在许多类之间存在某种关系。因此,并不是所有的错误都是均等的。人们宁愿错误地分入一个相关  的类别,也不愿错误地分入一个遥远的类别,这通常被称为层次分类(hierarchical classification)。
                - 层次结构相关性可能取决于模型的使用者计划如何使用模型；
            - 标记问题：
                - 多标签分类（multi-label classification）：学习预测不相互排斥的类别的问题称为多标签分类；
        - 搜索：
            - 有时，不仅仅希望输出一个类别或一个实值。在信息检索领域，我们希望对一组项目进行排序；
            - 该问题的一种可能的解决方案：首先为集合中的每个元素分配相应的相关性分数，然后检索评级最高的元素；（如 PageRank 算法）
        - 推荐系统：
            - 另一类与搜索和排名相关的问题是 推荐系统（recommender system），其目标是向特定用户进行”个性化“推荐；
            - 对于任何给定的用户，推荐系统都可以检索得分最高的对象集，然后将其推荐给用户。工业生产的推荐系统要先进得多，它会将详细的用户活动和项目特征考虑在内。推荐系统算法经过调整，可以捕捉一个人的偏好；
            - 推荐系统具有巨大的应用价值，但单纯用它作为预测模型仍存在一些缺陷。数据只包含”审查后的反馈“：用户更倾向于给他们感觉强烈的事物打分；如何处理审查、激励和反馈循环（陷入茧房）都是重要的开放性研究问题；
        - 序列学习：
            - 以上绝大多数问题都具有固定大小的输入和产生固定大小的输出。如果输入的样本之间没有任何关系，以上模型可能完美无缺。但是如果输入是连续的，模型可能就需要拥有”记忆“功能；
            - 序列学习是机器学习最令人兴奋的应用之一。序列学习需要摄取输入序列或预测输出序列，或两者兼有之。具体来说，输入和输出都是可变长度的序列；
            - 相关细分领域：标记和解析；自动语音识别；文本到语音；机器翻译；

- 无监督学习（unsupervised learning）：
    - 数据中不含有”目标“的机器学习问题通常被称为无监督学习；
    - 无监督学习分类：
        - 聚类（clustering）问题：在没有标签的情况下，给数据分类；
        - 主成分分析（principal component analysis）问题：找到少量的参数来准确地捕捉数据的线性相关属性；
        - 因果关系（causality）和 概率图模型（probabilistic graphical models）问题：描述观察到的许多数据的根本原因；根据经验数据发现关系；
        - 生成对抗性网络（generative adversarial networks）：提供一种合成数据的方法，甚至像图像和音频这样复杂的非结构化数据。潜在的统计机制是检查真实和虚假数据是否相同的测试，它是无监督学习的另一个重要而令人兴奋的领域；

- 离线学习（offline learning）：
    - 目前为止，不管是 监督学习 还是 无监督学习，都会预先获取大量数据，然后启动模型，不再与环境交互。
    - 这里所有学习都是在算法和环境断开后进行的，被称为 离线学习（offline learning）；
    - 优缺点：
        - 优点：这种简单的离线学习有它的魅力，其可以孤立地进行模式识别，而不必分心于其它问题；
        - 缺点：能解决的问题相当有限；

- 强化学习（reinforcement learning）：一类明确考虑与环境交互的问题；

    - 背景：
        - 期望人工智能（这里的人工智能是”智能代理“，而不仅是”预测模型“）不仅能够做出预测，而且能够与真实环境互动。与预测不同，”与真实环境互动“实际上会影响环境；
        - 因此，必须考虑到它的行为可能会影响未来的观察结果；
        - ”与真实环境互动“ 将打开一整套新的建模问题，譬如：
            - 环境还记得我们以前做过什么吗？
            - 环境是否有助于我们建模？例如，用户将文本读入语音识别器；
            - 环境是否想要打败模型？例如，一个对抗性的设置，如垃圾邮件过滤或玩游戏？
            - 环境是否重要？
            - 环境是否变化？例如，未来的数据是否总是与过去相似，还是随着时间的推移会发生变化？是自然变化还是响应我们的自动化工具而发生变化？
                - 当测试和训练数据不同时，该问题提出了 分布迁移（distribution shift）的问题；

    - 深度强化学习（deep reinforcement learning）：将深度学习应用于强化学习的问题，是非常热门的研究领域；
    - 在强化学习问题中,智能体(agent)在一系列的时间步骤上与环境交互。在每个特定时间点,智能体从环境  接收一些观察(observation),并且必须选择一个动作(action),然后通过某种机制(有时称为执行器)将  其传输回环境,最后智能体从环境中获得奖励(reward)。此后新一轮循环开始,智能体接收后续观察,并  选择后续操作,依此类推。
    - 强化学习的目标是产生一个好  的策略(policy)。强化学习智能体选择的“动作”受策略控制,即一个从环境观察映射到行动的功能。
    - 强化学习框架的通用性十分强大。例如,我们可以将任何监督学习问题转化为强化学习问题。
        - 假设有一个分类问题，可以创建一个强化学习智能体，每个分类对应一个”动作“；
        - 然后，可创建一个环境，该环境给予智能体的奖励。这个奖励与原始监督学习问题的损失函数是一致的；
    - 强化学习还可以解决许多监督学习无法解决的问题。
    - 强化学习必须处理 学分分配（credit assignment）问题：决定哪些行为是值得奖励的，哪些行为是需要惩罚的；
    - 强化学习可能还必须处理部分可观测性问题；
    - 在任何时间点上，强化学习智能体可能知道一个好的策略，但可能有许多更好的策略从未尝试过。强化学习智能体必须不断地做出选择：是应该利用当前最好的策略，还是探索新的策略空间（放弃一些短期回报来换取知识）；
    - 一般的强化学习问题是一个非常普遍的问题。智能体的动作会影响后续的观察,而奖励只与所选的动作相对  应。环境可以是完整观察到的,也可以是部分观察到的,解释所有这些复杂性可能会对研究人员要求太高。此  外,并不是每个实际问题都表现出所有这些复杂性。因此,学者们研究了一些特殊情况下的强化学习问题。
    - 强化学习分类：
        - 当环境可被完全观察到时，强化学习问题被称为 马尔可夫决策过程（markov decision process）；
        - 当状态不依赖于之前的操作时，称该问题为 上下文赌博机（contextual bandit problem）；
        - 当没有状态，只有一组最初未知回报的可用动作时，该问题就是经典的 多臂赌博机（multi-armed bandit problem）；


回归(regression)是能为一个或多个自变量与因变量之间关系建模的一类方法。在自然科学和社会科学领  域,回归经常用来表示输入和输出之间的关系。
在机器学习领域中的大多数任务通常都与预测(prediction)有关。当我们想预测一个数值时,就会涉及到  回归问题。
但不是所有的预测都是回归问题。在后面的章节中,我们将介绍分类问题。分类问题的目标是预  测数据属于一组类别中的哪一个。

给定特征估计目标的过程通常称为预测(prediction)或推断(inference)。

本书将尝试坚持使用预测这个词。虽然推断这个词已经成为深度学习的标准术语,但其实推断这个词有些用  词不当。在统计学中,推断更多地表示基于数据集估计参数。当深度学习从业者与统计学家交谈时,术语的  误用经常导致一些误解。

矢量化代码通常会带来数量级的加速。

由于历史原因,优化通常是说最小化而  不是最大化。

## 回归~分类

回归可以用于预测多少的问题。比如预测房屋被售出价格,或者棒球队可能获得的胜场数,又或者患者住院  的天数。

事实上,我们也对分类问题感兴趣:不是问“多少”,而是问“哪一个”:

通常,机器学习实践者用分类这个词来描述两个有微妙差别的问题:1. 我们只对样本的“硬性”类别感兴趣,  即属于哪个类别;2. 我们希望得到“软性”类别,即得到属于每个类别的概率。这两者的界限往往很模糊。  其中的一个原因是:即使我们只关心硬类别,我们仍然使用软类别的模型。

但是一般的分类问题并不与类别之间的自然顺序有关。幸运的是,统计学家很早以前就发明了一种表示分类  数据的简单方法:独热编码(one-hot encoding)。独热编码是一个向量,它的分量和类别一样多。类别对  应的分量设置为1,其他所有分量设置为0。

为了估计所有可能类别的条件概率,我们需要一个有多个输出的模型,每个类别对应一个输出。为了解决线  性模型的分类问题,我们需要和输出一样多的仿射函数(affine function)。每个输出对应于它自己的仿射函  数。

要将输出视为概率,我们必须保证在任何数据上的输出都是非负的且总和为1。此外,我们需要一个训练的目  标函数,来激励模型精准地估计概率。例如,在分类器输出0.5的所有样本中,我们希望这些样本是刚好有一  半实际上属于预测的类别。这个属性叫做校准(calibration)。


# 神经网络

到目前为止,我们只谈论了线性模型。尽管神经网络涵盖了更多更为丰富的模型,我们依然可以用描述神经  网络的方式来描述线性模型,从而把线性模型看作一个神经网络。首先,我们用“层”符号来重写这个模型。

深度学习从业者喜欢绘制图表来可视化模型中正在发生的事情。在 图3.1.2中,我们将线性回归模型描述为一  个神经网络。需要注意的是,该图只显示连接模式,即只显示每个输入如何连接到输出,隐去了权重和偏置  的值。

在 图3.1.2所示的神经网络中,输入为x1; : : : ; xd,因此输入层中的输入数(或称为特征维度,feature dimensionality)为d。网络的输出为o1,因此输出层中的输出数是1。需要注意的是,输入值都是已经给定的,并且  只有一个计算神经元。由于模型重点在发生计算的地方,所以通常我们在计算层数时不考虑输入层。也就是  说,图3.1.2中神经网络的层数为1。我们可以将线性回归模型视为仅由单个人工神经元组成的神经网络,或  称为单层神经网络。


**MLP**：
- 神经网络有点像C语言。C语言和任何其他现代编程语言一样,能够表达任何可计  算的程序。但实际上,想出一个符合规范的程序才是最困难的部分。
- 而且,虽然一个单隐层网络能学习任何函数,但并不意味着我们应该尝试使用单隐藏层网络来解决所有问题。  事实上,通过使用更深(而不是更广)的网络,我们可以更容易地逼近许多函数。

~ 通用近似定理


# 线性模型局限性-例子
------

例如,线性意味着单调假设:任何特征的增大都会导致模型输出的增大(如果对应的权重为正),或者导致模  型输出的减小(如果对应的权重为负)。有时这是有道理的。例如,如果我们试图预测一个人是否会偿还贷款。  我们可以认为,在其他条件不变的情况下,收入较高的申请人比收入较低的申请人更有可能偿还贷款。但是,  虽然收入与还款概率存在单调性,但它们不是线性相关的。收入从0增加到5万,可能比从100万增加到105万  带来更大的还款可能性。处理这一问题的一种方法是对我们的数据进行预处理,使线性变得更合理,如使用  收入的对数作为我们的特征。

然而我们可以很容易找出违反单调性的例子。例如,我们想要根据体温预测死亡率。对体温高于37摄氏度的  人来说,温度越高⻛险越大。然而,对体温低于37摄氏度的人来说,温度越高⻛险就越低。在这种情况下,我  们也可以通过一些巧妙的预处理来解决问题。例如,我们可以使用与37摄氏度的距离作为特征。

但是,如何对猫和狗的图像进行分类呢?增加位置(13; 17)处像素的强度是否总是增加(或降低)图像描绘狗  的似然?对线性模型的依赖对应于一个隐含的假设,即区分猫和狗的唯一要求是评估单个像素的强度。在一  个倒置图像后依然保留类别的世界里,这种方法注定会失败。

与我们前面的例子相比,这里的线性很荒谬,而且我们难以通过简单的预处理来解决这个问题。这是因为任  何像素的重要性都以复杂的方式取决于该像素的上下文(周围像素的值)。我们的数据可能会有一种表示,这  种表示会考虑到我们在特征之间的相关交互作用。在此表示的基础上建立一个线性模型可能会是合适的,但  我们不知道如何手动计算这么一种表示。对于深度神经网络,我们使用观测数据来联合学习隐藏层表示和应  用于该表示的线性预测器。



# 过拟合 & 欠拟合
------

过拟合、欠拟合和模型选择。为了解决这些问题,本章将介绍权重衰减和暂退法等正则化技术。我们还将讨  论数值稳定性和参数初始化相关的问题,这些问题是成功训练深度网络的关键。

关于模型计算性能、可伸缩性和效率相关的问题,我们将放  在后面的章节中讨论。

## 过拟合

当我们训练容量较大的模型时,我们面临着过拟合的⻛险。

实际  上,限制特征的数量是缓解过拟合的一种常用技术。然而,简单地丢弃特征对这项工作来说可能过于生硬。

仅仅通过简单的限制特征数量(在多项式回归中体现为限制阶数),可能仍然使模型在过简单和过复杂中徘徊,我们需要一个  更细粒度的工具来调整函数的复杂性,使其达到一个合适的平衡位置。

**过拟合的更多解决方法**：

到目前为止,我们只接触到一个简单线性函数的概念。此外,由什么构成一个简单的非线性函数可能是一个  更复杂的问题。例如,再生核希尔伯特空间(RKHS)65 允许在非线性环境中应用为线性函数引入的工具。不  幸的是,基于RKHS的算法往往难以应用到大型、高维的数据。在这本书中,我们将默认使用简单的启发式方  法,即在深层网络的所有层上应用权重衰减。












