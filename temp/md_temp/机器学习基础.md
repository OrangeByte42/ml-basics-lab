# 基本术语

- 数据集（dataset）；
    - 训练数据集（training dataset）/ 训练集（training set）：
        - 用于拟合模型参数的数据集；
        - 用于通过最小化总损失来学习模型参数的最佳值的数据集，该数据集由一些为训练而收集的样本组成；

    - 测试数据集（test dataset）/ 测试集（test set）：
        - 用于评估拟合的模型的数据集；
        - 在训练数据集上表现良好的模型，并不一定在“新数据集”上有同样的性能。此处“新数据集”通常称为 测试数据集；

- 参数（parameter）；
- 模型（model）：任一调整参数后获得“最佳参数集”的程序；
- 模型族：通过操作参数而生成的所有不同程序（输入-输出映射）的集合；
- 学习算法（Learning Algorithm）：使用数据集来选择参数的元程序；
- 学习（learning）：训练模型的过程，通过该过程可以发现正确的参数集，从而使得模型强制执行所需的行为。即使用数据训练模型；
    - 这里所说的“学习”，是指自主提高模型完成某些任务的效能；
- 训练（train）；
    - 训练通常包括下述步骤：
        1. 从一个随机初始化参数的模型开始，这个模型基本没有“智能”；
        2. 获取一些数据样本；
        3. 调整参数，使模型在这些样本中表现得很好；
        4. 重复步骤2、3，直到模型在任务中表现得令人满意；
- 数据编程（programming with data）：通过用数据集来确定程序行为；
- 深度学习（Deep Learning）；
    - 深度学习是机器学习的一个主要分支；
- 过拟合（overfitting）：当一个模型在训练集上表现良好，但不能推广到测试集的情况；

## 机器学习中的关键组件

首先介绍一些核心组件。无论什么类型的机器学习问题，都会遇到这些组件：
1. 可用来学习的数据（data）；
2. 如何转换数据的模型（model）；
3. 一个目标函数（objective function），用来量化模型的有效性；
4. 调整模型参数以优化目标函数的算法（algorithm）；

### 数据

- 样本（example, sample）：每个数据集由一个个样本组成；
    - 样本也被称作 数据点（data point）或 数据实例（data instance）；
    - 通常每个样本由一组成为特征（features，或协变量（covariates））的属性组成；
    - 数据的 维数（dimensionality）：
        - 当每个样本的特征类别数量都是相同的时候，其特征向量是固定长度的，这个长度被称为数据的维数；
        - 固定长度的特征向量是一个方便的属性，它可以用来量化学习大量样本；
        - 然而，并不是所有的数据都可以用“固定长度”的向量表示；
- 独立同分布（independently and identically distributed, i.i.d）：大多时候，样本遵循独立同分布；
- 标签（label）：也被称为 目标（target）；

与传统机器学习方法相比,深度学习的一个主要优势是可以处理不同⻓度的数据。

一般来说,拥有越多数据的时候,工作就越容易。更多的数据可以被用来训练出更强大的模型,从而减少对  预先设想假设的依赖。数据集的由小变大为现代深度学习的成功奠定基础。在没有大数据集的情况下,许多  令人兴奋的深度学习模型黯然失色。就算一些深度学习模型在小数据集上能够工作,但其效能并不比传统方  法高。

请注意,仅仅拥有海量的数据是不够的,我们还需要正确的数据。如果数据中充满了错误,或者如果数据的  特征不能预测任务目标,那么模型很可能无效。有一句古语很好地反映了这个现象:“输入的是垃圾,输出的  也是垃圾。”(“Garbage in, garbage out.”)此外,糟糕的预测性能甚至会加倍放大事态的严重性。

当数据不具有充  分代表性,甚至包含了一些社会偏⻅时,模型就很有可能有偏⻅。

大多数机器学习会涉及到数据的转换。

### 模型

深度学习与经典方法的区别主要在于:前者关注的功能强大的模型,这些模型由神经  网络错综复杂的交织在一起,包含层层数据转换,因此被称为深度学习(deep learning)。

### 目标函数

- 目标函数（objective function）：对模型优劣程度的度量，在大多数情况是“可优化”的；
    - 通常定义一个目标函数，并希望优化它到最低点；
    - 这个函数有时被称为 损失函数（loss function / cost function）；
    - 试图预测数值时，最常见的损失函数是 平方误差（squared error）：即预测值与实际值之差的平方；
    - 解决分类问题时，最常见的目标函数是 最小化错误率：即预测与实际情况不符的样本比例；
    - 有些目标（如平方误差）很容易被优化，有些目标（如错误率）由于不可微性或其它复杂性难以直接优化。在这些情况下，通常会优化替代目标；
    - 通常，损失函数是根据模型参数定义的，并取决于数据集；

### 优化算法

当 获得数据源及其表示、模型 和 合适的损失函数，接下来就需要一种算法，其能够搜索出最佳参数，以最小化损失函数；

- 梯度下降（gradient descent）：
    - 大多流行的优化算法通常基于该基本优化方法；
    - 在每个步骤中，梯度下降法都会检查每个参数，看看如果仅对该参数进行少量变动，训练集损失会朝哪个方向移动，然后在减少损失的方向上优化参数；



## 机器学习问题分类

- 监督学习（supervised learning）：
    - 擅长在 “给定输入特征” 的情况下预测标签。每个 “特征-标签” 对都称为一个样本（example）。有时即使标签未知，样本也可以指代输入特征；
    - 目标是生成一个模型，能够将任何输入特征映射到标签（即预测“估计给定输入特征的标签”的条件概率）；
    - 虽然监督学习只是几大类机器学习问题之一，但在工业中，大部分机器学习的成功应用都使用了监督学习。因为在一定程度上，许多重要的任务都可清晰地描述为：在给定一组特定的可用数据的情况下，估计未知事物的概率；
    - 学习过程一般分为三大步骤：
        1. 从已知大量数据样本中随机选取一个子集，为每个样本获取真实标签。有时，这些样本已有标签；有时，这些样本可能需要人工标记标签。这些输入和相应的标签一起构成了训练数据集；
        2. 选择有监督的学习算法，它将训练数据集作为输入，并输出一个“已完成学习的模型”；
        3. 将之前没有见过的样本特征放到这个“已完成学习的模型”中，使用模型的输出作为相应标签的预测；
    - 监督学习任务分类：
        - 回归（regression）：
            - 最简单的监督学习任务之一。当标签取任意数值时，称之为回归问题，此时目标是生成一个模型，使它的预测非常接近实际标签值；
            - 生活中的许多问题都可归类为回归问题。总而言之，判断回归问题的一个很好的经验法则是，任何有关“有多少”的问题很可能就是回归问题；
            - 回归是训练一个回归函数来输出一个数值；
        - 分类（classification）：判断属于“哪一个”的问题称之为分类问题；
            - 分类问题希望模型能够预测样本属于哪个类别（category，正式称为类（class））；
            - 最简单的分类问题是只有两类，这被称之为二项分类（binomial classification）；
            - 分类是训练一个分类器来输出预测的类别。对于“是”或“不是”这类硬分类预测，可使用概率语言来理解模型。预测类别的概率大小传达了一种模型的不确定性；
            - TODO：运用不确定性概念的算法；
            - 当有两个以上的类别时，将问题称为 多项分类（multiclass classification）问题；
            - 与解决回归问题不同，分类问题的常见损失函数被称为交叉熵（cross-entropy）；
            - 需要注意的是，最常见/概率最大的类别不一定是最终用于决策的类别；
            - 层次分类（hierarchical classification）：
                - 分类可能变得比二项分类、多项分类复杂得多。例如,有一些分类任务的变体可以用于寻找层次结构,层次  结构假定在许多类之间存在某种关系。因此,并不是所有的错误都是均等的。人们宁愿错误地分入一个相关  的类别,也不愿错误地分入一个遥远的类别,这通常被称为层次分类(hierarchical classification)。
                - 层次结构相关性可能取决于模型的使用者计划如何使用模型；
            - 标记问题：
                - 多标签分类（multi-label classification）：学习预测不相互排斥的类别的问题称为多标签分类；
        - 搜索：
            - 有时，不仅仅希望输出一个类别或一个实值。在信息检索领域，我们希望对一组项目进行排序；
            - 该问题的一种可能的解决方案：首先为集合中的每个元素分配相应的相关性分数，然后检索评级最高的元素；（如 PageRank 算法）
        - 推荐系统：
            - 另一类与搜索和排名相关的问题是 推荐系统（recommender system），其目标是向特定用户进行”个性化“推荐；
            - 对于任何给定的用户，推荐系统都可以检索得分最高的对象集，然后将其推荐给用户。工业生产的推荐系统要先进得多，它会将详细的用户活动和项目特征考虑在内。推荐系统算法经过调整，可以捕捉一个人的偏好；
            - 推荐系统具有巨大的应用价值，但单纯用它作为预测模型仍存在一些缺陷。数据只包含”审查后的反馈“：用户更倾向于给他们感觉强烈的事物打分；如何处理审查、激励和反馈循环（陷入茧房）都是重要的开放性研究问题；
        - 序列学习：
            - 以上绝大多数问题都具有固定大小的输入和产生固定大小的输出。如果输入的样本之间没有任何关系，以上模型可能完美无缺。但是如果输入是连续的，模型可能就需要拥有”记忆“功能；
            - 序列学习是机器学习最令人兴奋的应用之一。序列学习需要摄取输入序列或预测输出序列，或两者兼有之。具体来说，输入和输出都是可变长度的序列；
            - 相关细分领域：标记和解析；自动语音识别；文本到语音；机器翻译；

- 无监督学习（unsupervised learning）：
    - 数据中不含有”目标“的机器学习问题通常被称为无监督学习；
    - 无监督学习分类：
        - 聚类（clustering）问题：在没有标签的情况下，给数据分类；
        - 主成分分析（principal component analysis）问题：找到少量的参数来准确地捕捉数据的线性相关属性；
        - 因果关系（causality）和 概率图模型（probabilistic graphical models）问题：描述观察到的许多数据的根本原因；根据经验数据发现关系；
        - 生成对抗性网络（generative adversarial networks）：提供一种合成数据的方法，甚至像图像和音频这样复杂的非结构化数据。潜在的统计机制是检查真实和虚假数据是否相同的测试，它是无监督学习的另一个重要而令人兴奋的领域；

- 离线学习（offline learning）：
    - 目前为止，不管是 监督学习 还是 无监督学习，都会预先获取大量数据，然后启动模型，不再与环境交互。
    - 这里所有学习都是在算法和环境断开后进行的，被称为 离线学习（offline learning）；
    - 优缺点：
        - 优点：这种简单的离线学习有它的魅力，其可以孤立地进行模式识别，而不必分心于其它问题；
        - 缺点：能解决的问题相当有限；

- 强化学习（reinforcement learning）：一类明确考虑与环境交互的问题；

    - 背景：
        - 期望人工智能（这里的人工智能是”智能代理“，而不仅是”预测模型“）不仅能够做出预测，而且能够与真实环境互动。与预测不同，”与真实环境互动“实际上会影响环境；
        - 因此，必须考虑到它的行为可能会影响未来的观察结果；
        - ”与真实环境互动“ 将打开一整套新的建模问题，譬如：
            - 环境还记得我们以前做过什么吗？
            - 环境是否有助于我们建模？例如，用户将文本读入语音识别器；
            - 环境是否想要打败模型？例如，一个对抗性的设置，如垃圾邮件过滤或玩游戏？
            - 环境是否重要？
            - 环境是否变化？例如，未来的数据是否总是与过去相似，还是随着时间的推移会发生变化？是自然变化还是响应我们的自动化工具而发生变化？
                - 当测试和训练数据不同时，该问题提出了 分布迁移（distribution shift）的问题；

    - 深度强化学习（deep reinforcement learning）：将深度学习应用于强化学习的问题，是非常热门的研究领域；
    - 在强化学习问题中,智能体(agent)在一系列的时间步骤上与环境交互。在每个特定时间点,智能体从环境  接收一些观察(observation),并且必须选择一个动作(action),然后通过某种机制(有时称为执行器)将  其传输回环境,最后智能体从环境中获得奖励(reward)。此后新一轮循环开始,智能体接收后续观察,并  选择后续操作,依此类推。
    - 强化学习的目标是产生一个好  的策略(policy)。强化学习智能体选择的“动作”受策略控制,即一个从环境观察映射到行动的功能。
    - 强化学习框架的通用性十分强大。例如,我们可以将任何监督学习问题转化为强化学习问题。
        - 假设有一个分类问题，可以创建一个强化学习智能体，每个分类对应一个”动作“；
        - 然后，可创建一个环境，该环境给予智能体的奖励。这个奖励与原始监督学习问题的损失函数是一致的；
    - 强化学习还可以解决许多监督学习无法解决的问题。
    - 强化学习必须处理 学分分配（credit assignment）问题：决定哪些行为是值得奖励的，哪些行为是需要惩罚的；
    - 强化学习可能还必须处理部分可观测性问题；
    - 在任何时间点上，强化学习智能体可能知道一个好的策略，但可能有许多更好的策略从未尝试过。强化学习智能体必须不断地做出选择：是应该利用当前最好的策略，还是探索新的策略空间（放弃一些短期回报来换取知识）；
    - 一般的强化学习问题是一个非常普遍的问题。智能体的动作会影响后续的观察,而奖励只与所选的动作相对  应。环境可以是完整观察到的,也可以是部分观察到的,解释所有这些复杂性可能会对研究人员要求太高。此  外,并不是每个实际问题都表现出所有这些复杂性。因此,学者们研究了一些特殊情况下的强化学习问题。
    - 强化学习分类：
        - 当环境可被完全观察到时，强化学习问题被称为 马尔可夫决策过程（markov decision process）；
        - 当状态不依赖于之前的操作时，称该问题为 上下文赌博机（contextual bandit problem）；
        - 当没有状态，只有一组最初未知回报的可用动作时，该问题就是经典的 多臂赌博机（multi-armed bandit problem）；







