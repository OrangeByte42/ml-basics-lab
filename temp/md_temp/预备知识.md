# Anaconda

- 创建环境：conda create --name d2l python=3.9 -y
- 激活环境：conda activate d2l





# 概述

所有机器学习方法都涉及从数据中提取信息。因此,我们  先学习一些关于数据的实用技能,包括存储、操作和预处理数据。

机器学习通常需要处理大型数据集。我们可以将某些数据集视为一个表,其中表的行对应样本,列对应属性。

为了能够完成各种数据操作,我们需要某种方法来存储和操作数据。通常,我们需要做两件重要的事:(1)  获取数据;(2)将数据读入计算机后对其进行处理。如果没有某种方法来存储数据,那么获取数据是没有意  义的。

我们想在这些数据上执行数学运算,其中最简单且最有用的操作  是按元素(elementwise)运算。它们将标准标量运算符应用于数组的每个元素。对于将两个数组作为输入  的函数,按元素运算将二元运算符应用于两个数组中的每对位置对应的元素。我们可以基于任何从标量到标  量的函数来创建按元素函数。

在某些情况下,即使形状不同,  我们仍然可以通过调用 广播机制(broadcasting mechanism)来执行按元素操作。这种机制的工作方式如  下:

1. 通过适当复制元素来扩展一个或两个数组，以便在转换之后，两个张量具有相同的形状；
2. 对生成的数组执行按元素操作；

在大多数情况下，我们沿着数组中长度为 1 的轴进行广播；

就像在任何其他Python数组中一样,张量中的元素可以通过索引访问。与任何Python数组一样:第一个元素  的索引是0,最后一个元素索引是-1;可以指定范围以包含第一个元素和最后一个之前的元素。

# 使用 PyTorch

导入 `torch`：

```python
import torch
```

# 张量

- 无论使用哪个深度学习框架，它的张量类（在 MXNet 中为 ndarray，在 PyTorch 和 TensorFlow 中为 Tensor）都与 NumPy 的 ndarray 类似。但深度学习框架比 NumPy 的 ndarray 多一些重要功能，这些功能使得张量类更适合深度学习：
    - GPU 很好地支持加速计算，而 NumPy 仅支持 CPU 计算；
    - 张量类支持自动微分；
- $n$ 维数组，也称为张量。张量表示一个由数值组成的数组，这个数组可能有多个维度；
    - 具有一个轴的张量对应数学上的 向量（vector）；
    - 具有两个轴的张量对应数学上的 矩阵（matrix）；
    - 具有两个轴以上的张量没有特殊的数学名称；
- 张量中的每个值都称为张量的元素（element）；
- 除非额外指定，新的张量将存储在内存中，并采用基于 CPU 的计算；

### 节省内存

- 运行一些操作可能会导致为新结果分配内存。例如,如果我们用Y = X + Y,我们将取消引用Y指向的张量,  而是指向新分配的内存处的张量。
- 这可能是不可取的,原因有两个:
    1. 首先,我们不想总是不必要地分配内存。在机器学习中,我们可能有数百兆的参数,并且在一秒内多次  更新所有参数。通常情况下,我们希望原地执行这些更新;
    2. 如果我们不原地更新,其他引用仍然会指向旧的内存位置,这样我们的某些代码可能会无意中引用旧  的参数。
- 两种解决方法：
    1. 幸运的是,执行原地操作非常简单。我们可以使用切片表示法将操作的结果分配给先前分配的数组,例如`Y[:]  = <expression>`；
    2. 如果在后续计算中没有重复使用X,我们也可以使用X[:] = X + Y或X += Y来减少操作的内存开销；

将深度学习框架定义的张量转换为NumPy张量(ndarray)很容易,反之也同样容易。torch张量和numpy数  组将共享它们的底层内存,就地操作更改一个张量也会同时更改另一个张量。

要将大小为1的张量转换为Python标量,我们可以调用item函数或Python的内置函数。

深度学习存储和操作数据的主要接口是张量(n维数组)。它提供了各种功能,包括基本数学运算、广  播、索引、切片、内存节省和转换其他Python对象。

# 数据预处理

为了能用深度学习来解决现实世界的问题,我们经常从预处理原始数据开始,而不是从那些准备好的张量格  式数据开始。在Python中常用的数据分析工具中,我们通常使用pandas软件包。像庞大的Python生态系统中  的许多其他扩展包一样,pandas可以与张量兼容。

注意,“NaN”项代表缺失值。为了处理缺失的数据,典型的方法包括插值法和删除法：

- 插值法：用一个替代值弥补缺失值；
- 删除法：直接忽略缺失值；

pandas软件包是Python中常用的数据分析工具中,pandas可以与张量兼容。

用pandas处理缺失的数据时,我们可根据情况选择用插值法和删除法。



当向  量表示数据集中的样本时,它们的值具有一定的现实意义。



# 数学应用相关

## ~ 线性代数

矩阵是有用的数据结构:它们允许我们组织具有不同模式的数据。

为什么通常以行向量来组织样本？

因此,尽管单个向量的默认方向是列向量,但在表示表格数据集的矩阵中,将每个数据样本作为矩  阵中的行向量更为常⻅。后面的章节将讲到这点,这种约定将支持常⻅的深度学习实践。例如,沿着张量的  最外轴,我们可以访问或遍历小批量的数据样本。

标量、向量、矩阵和任意数量轴的张量(本小节中的“张量”指代数对象)有一些实用的属性。例如,从按  元素操作的定义中可以注意到,任何按元素的一元运算都不会改变其操作数的形状。同样,给定具有相同形  状的任意两个张量,任何按元素二元运算的结果都将是相同形状的张量。例如,将两个相同形状的矩阵相加,  会在这两个矩阵上执行元素加法。

点积在很多场合都很有用。例如，给定一组由向量 $\mathbf{x} \in \mathbb{R}^{d}$ 表示的值，和一组由 $\mathbf{w} \in \mathbb{R}^{d}$ 表示的权重。$\mathbf{x}$ 中的值根据权重 $\mathbf{w}$ 的加权和，可以表示为点积 $\mathbf{x}^{T}\mathbf{w}$。
- 当权重为非负数且和为 $1$（即 $\sum\limits_{i=1}^{d}w_i=1$）时，点积表示加权平均（weighted average）；
- 将两个向量规范化得到单位长度后，点积表示它们夹角的余弦；

我们可以把一个矩阵 $\mathbf{A} \in \mathbb{R}^{m \times n}$ 乘法看作一个从 $\mathbb{R}^{n}$ 到 $\mathbb{R}^{m}$ 的转换。这些转换是非常有用的，例如可以用方阵的乘法表示旋转。后续章节将讲到,我们也可以使用矩阵-向量积来描述在给定前一层的值时,求解神经  网络每一层所需的复杂计算。

范数听起来很像距离的度量。欧几里得距离和毕达哥拉斯定理中的非负性概念和三⻆不等式可能会给出一些  启发。

## ~ 微积分

我们首先讨论导数的计算,这是几乎所有深度学习优化算法的关键步骤。在深度学习中,我们通常选择对于  模型参数可微的损失函数。简而言之,对于每个参数,如果我们把这个参数增加或减少一个无穷小的量,可  以知道损失会以多快的速度增加或减少。

在深度学习中,函数通常依赖于许多变量。

正如我们之后将看到的,梯度对于设计深度学习中的优化算法  有很大用处。

然而,上面方法可能很难找到梯度。这是因为在深度学习中,多元函数通常是复合(composite)的,所以难  以应用上述任何规则来微分这些函数。幸运的是,链式法则可以被用来微分复合函数。

## ~ 概率

简单地说,机器学习就是做出预测。

概率给了我们一种正式的途径来说明我们的确定性水平。

概率是一种灵活的语言,用于说明  我们的确定程度,并且它可以有效地应用于广泛的领域中。

对于每个值,一种自然的方法是将  它出现的次数除以投掷的总次数,即此事件(event)概率的估计值。大数定律(law of large numbers)告  诉我们:随着投掷次数的增加,这个估计值会越来越接近真实的潜在概率。

在估计一个骰子的公平性时,我们希望从同一分布中生成多个样本。如果用Python的for循环来完成这个任  务,速度会慢得惊人。因此我们使用深度学习框架的函数同时抽取多个样本,得到我们想要的任意形状的独  立样本数组。

概率可能是反直觉的；


# Temp-线性回归（仿射变换 & 最小二乘法解析解）

仿射变换

在我们开始考虑如何用模型拟合(fit)数据之前,我们需要确定一个拟合程度的度量。损失函数(loss function)  能够量化目标的实际值与预测值之间的差距。通常我们会选择非负数作为损失,且数值越小表示损失越小,  完美预测时的损失为0。回归问题中最常用的损失函数是平方误差函数。

线性回归刚好是一个很简单的优化问题。与我们将在本书中所讲到的其他大部分模型不同,线性回归的解可  以用一个公式简单地表达出来,这类解叫作解析解(analytical solution)。首先,我们将偏置 $b$ 合并到参数 $\mathbf{w}$ 中,  合并方法是在包含所有参数的矩阵中附加一列。我们的预测问题是最小化 ${\parallel \mathbf{y} - \mathbf{X}\mathbf{w}\parallel}^{2}$。这在损失平面上只有  一个临界点,这个临界点对应于整个区域的损失极小点。将损失关于 $\mathbf{w}$ 的导数设为 $0$,得到解析解:
$$
\mathbf{w}^{\ast} = {(\mathbf{X}^{\top}\mathbf{X})}^{-1}\mathbf{X}^{\top}\mathbf{y}
$$

像线性回归这样的简单问题存在解析解,但并不是所有的问题都存在解析解。解析解可以进行很好的数学分析,但解析解对问题的限制很严格,导致它无法广泛应用在深度学习里。

在训练softmax回归模型后,给出任何样本特征,我们可以预测每个输出类别的概率。通常我们使用预测概  率最高的类别作为输出类别。如果预测与实际类别(标签)一致,则预测是正确的。在接下来的实验中,我  们将使用精度(accuracy)来评估模型的性能。精度等于正确预测数与预测总数之间的比率。



# 随机梯度下降法（P88-P89）

Omit




虽然现代的深度学习  框架几乎可以自动化地进行所有这些工作,但从零开始实现可以确保我们真正知道自己在做什么。同时,了  解更细致的工作原理将方便我们自定义模型、自定义层或自定义损失函数。

回想一下,训练模型时要对数据集进行遍历,每次抽取一小批量样本,并使用它们来更新我们的模型。由于  这个过程是训练机器学习算法的基础,所以有必要定义一个函数,该函数能打乱数据集中的样本并以小批量  方式获取数据。

当我们运行迭代时,我们会连续地获得不同的小批量,直至遍历完整个数据集。上面实现的迭代对教学来说  很好,但它的执行效率很低,可能会在实际问题上陷入麻烦。例如,它要求我们将所有数据加载到内存中,并  执行大量的随机内存访问。在深度学习框架中实现的内置迭代器效率要高得多,它可以处理存储在文件中的  数据和数据流提供的数据。

通常,我们利用GPU并行运算的优势,处理合理大小的“小批量”。每个样本都可以并行地进行模型计算,且  每个样本损失函数的梯度也可以被并行计算。GPU可以在处理几百个样本时,所花费的时间不比处理一个样  本时多太多。

当我们运行迭代时,我们会连续地获得不同的小批量,直至遍历完整个数据集。上面实现的迭代对教学来说  很好,但它的执行效率很低,可能会在实际问题上陷入麻烦。例如,它要求我们将所有数据加载到内存中,并  执行大量的随机内存访问。在深度学习框架中实现的内置迭代器效率要高得多,它可以处理存储在文件中的  数据和数据流提供的数据。

在初始化参数之后,我们的任务是更新这些参数,直到这些参数足够拟合我们的数据。每次更新都需要计算  损失函数关于模型参数的梯度。有了这个梯度,我们就可以向减小损失的方向更新每个参数。因为手动计算  梯度很枯燥而且容易出错,所以没有人会手动计算梯度。我们使用 2.5节中引入的自动微分来计算梯度。


# Softmax

回想一下,实现softmax由三个步骤组成:
1. 对每个项求幂(使用exp);
2. 对每一行求和(小批量中每个样本是一行),得到每个样本的规范化常数;
3. 将每一行除以其规范化常数,确保结果的和为1。

在查看代码之前,我们回顾一下Softmax表达式 分母或规范化常数,有时也称为配分函数(其对数称为对数-配分函数)。该名称来自统计物理学55中一个模  拟粒子群分布的方程。



