# 数学符号规范

## 数字

- $x$：标量；
- $\mathbf{x}$：向量；
- $\mathbf{X}$：矩阵；
- $\mathsf{X}$：张量；
- $\mathbf{I}$：单位矩阵；
- $x_i, {[x]}_i$：向量 $\mathbf{x}$ 第 $i$ 个元素；
- $x_{ij}, {[\mathbf{X}]}_{ij}$：矩阵 $\mathbf{x}$ 第 $i$ 行第 $j$ 列的元素；

## 集合论

- $\mathcal{X}$：集合；
- $\mathbb{Z}$：整数集合；
- $\mathbb{R}$：实数集合；
- $\mathbb{R}^n$：$n$ 维实数向量集合；
- $\mathbb{R}^{a\times b}$：包含 $a$ 行和 $b$ 列的实数矩阵集合；
- $\mathcal{A}\cup \mathcal{B}$：集合 $\mathcal{A}$ 和 $\mathcal{B}$ 的并集；
- ${\mathcal{A}}\cap{\mathcal{B}}$：集合 $\mathcal{A}$ 和 $\mathcal{B}$ 的交集；
- ${\mathcal{A}} \setminus {\mathcal{B}}$：集合 $\mathcal{A}$ 与 $\mathcal{B}$ 相减，$\mathcal{B}$ 关于 $\mathcal{A}$ 的相对补集；

## 函数和运算符

- $f(\cdot)$：函数；
- $\log(\cdot)$：自然对数；
- $\exp(\cdot)$：指数函数；
- $\mathbf{1}_{\mathcal{X}}$：指示函数；
- ${(\cdot)}^\top$：向量或矩阵的转置；
- $\mathbf{X}^{-1}$：矩阵的逆；
- $\odot$：按元素相乘；
- $[\cdot,\cdot]$：连结；
- $|\mathcal{X}|$：集合的基数；
- ${\parallel\cdot\parallel}_p$​：$L_p$ 正则；
- $\parallel\cdot\parallel$：$L_2$ 正则；
- $\left\langle\mathbf{x},\mathbf{y}\right\rangle$：向量 $\mathbf{x}$ 和 $\mathbf{y}$ 的点积；
- $\sum$：连加；
- $\prod$：连乘；
- $\stackrel{\mathrm{def}}{=}$：定义；

## 微积分

- $\frac{d y}{d x}$：$y$ 关于 $x$ 的导数；
- $\frac{\partial y}{\partial x}$：$y$ 关于 $x$ 的偏导数；
- $\nabla_{x}y$：$y$ 关于 $\mathbf{x}$ 的梯度；
- $\int_{a}^{b} f(x)\ dx$：$f$ 在 $a$ 到 $b$ 区间上关于 $x$ 的定积分；
- $\int f(x)\ dx$：$f$ 关于 $x$ 的不定积分；

## 概率与信息论

- $P(\cdot)$：概率分布；
- $z \sim P$：随机变量 $z$ 具有概率分布 $P$；
- $P(X \mid Y)$：$X \mid Y$ 的条件概率；
- $p(x)$：概率密度函数；
- $E_{x}[f(x)]$：函数 $f$ 对 $x$ 的数学期望；
- $X \perp Y$：随机变量 $X$ 和 $Y$ 是独立的；
- $X \perp Y \mid Z$：随机变量 $X$ 和 $Y$ 在给定随机变量 $Z$ 的条件下是独立的；
- $\mathrm{Var}(X)$：随机变量 $X$ 的方差；
- $\sigma_{X}$：随机变量 $X$ 的标准差；
- $\mathrm{Cov}(X,Y)$：随机变量 $X$ 和 $Y$ 的协方差；
- $\rho(X,Y)$：随机变量 $X$ 和 $Y$ 的相关性；
- $H(X)$：随机变量 $X$ 的熵；
- $D_{\mathrm{KL}}(P\parallel Q)$：$P$ 和 $Q$ 的 KL-散度；

## 复杂度

- $\mathcal{O}$：大 $O$ 标记；



# 数学定义

## 线性代数

- 标量（scalar）：仅包含一个数值。一般采用普通小写字母表示，如 $x$、$y$ 和 $z$；

- 变量（variable）：表示未知的数值（标量/张量）；

- 空间（space）：如用 $\mathbb{R}$ 表示所有（连续）实数标量的空间；

- 符号 $\in$ 称为“属于”，其表示 “是集合中的成员”，例如 $x, y \in \{0, 1\}$ 可用于表明 $x$ 和 $y$ 是值只能为 $0$ 或 $1$ 的数字，表达式 $x \in \mathbb{R}$ 是表示 $x$ 是一个实值标量的正式形式；

- 向量（vector）：
    - 由标量值组成的列表，这些标量值被称为向量的 元素（element）/ 分量（component）。数学表示法中，向量通常记为粗体、小写的符号，如 $\mathbf{x}$、$\mathbf{y}$ 和 $\mathbf{z}$；
    - 大量文献认为，列向量是向量的默认方向。在数学中，向量 $\mathbf{x}$ 可写成如下形式，其中 $x_1, \dots, x_n$ 是向量的元素；
        $$
        \mathbf{x}={\left[\begin{array}{c}
            {x_{1}}\\ {x_{2}}\\ {\vdots}\\ {x_{n}}\end{array}
        \right]}
        $$

    - 向量只是一个数字数组，就像每个数组都有一个长度一样，每个向量也是如此。在数学表示法中，如果我们想说一个向量 $\mathbf{x}$ 由 $n$ 个实值标量组成，可将其表示为 $\mathbf{x} \in \mathbb{R}^{n}$。向量的长度通常称为 向量的维度（dimension）；
    - 区分：
        - 向量/轴 的维度被用来表示 向量/轴 的长度，即 向量/轴 的元素数量；
        - 张量 的维度被用来表示 张量 具有的轴数，即张量的某个轴的维数就是这个轴的长度；

- 矩阵（matrix）：

    - 正如 向量 将 标量 从零阶推广到一阶，矩阵 将 向量 从一阶推广到二阶。矩阵等价于具有两个轴的张量/二维张量，通常用粗体、大写字母来表示，如 $\mathbf{X}$、$\mathbf{Y}$ 和 $\mathbf{Z}$；
    - 数学表示法使用 $\mathbf{A} \in \mathbb{R}^{m \times n}$ 来表示矩阵 $\mathbf{A}$，其由 $m$ 行和 $n$ 列的实值标量组成。可将任意矩阵 $\mathbf{A} \in \mathbb{R}^{m \times n}$ 视为一个表格，其中每个元素 $a_{ij}$ 属于第 $i$ 行第 $j$ 列：
    $$
    \mathbf{A}={\left[\begin{array}{c c c c}
        {a_{11}} & {a_{12}} & {\cdots} & {a_{1n}}\\
        {a_{21}} & {a_{22}} & {\cdots} & {a_{2n}}\\
        {\vdots} & {\vdots} & {\ddots} & {\vdots}\\
        {a_{m1}} & {a_{m2}} & {\cdots} & {a_{m n}}
    \end{array}\right]}
    $$
    - 对于任意 $\mathbf{A} \in \mathbb{R}^{m \times n}$，$\mathbf{A}$ 的形状是 $(m,n)$ 或 $m \times n$。当矩阵具有相同数量的行和列时，其形状将变为正方形；因此，它被称为方阵（square matrix）；
    - 可通过 行索引 $(i)$ 和 列索引 $(j)$ 来访问矩阵中的标量元素 $a_{ij}$，例如 ${[\mathbf{A}]}_{ij}$。若未给出矩阵 $\mathbf{A}$ 的标量元素，则可简单地使用矩阵 $\mathbf{A}$ 的小写字母索引下标 $a_{ij}$ 来引用 ${[\mathbf{A}]}_{ij}$。为了表示起来简单，只有在必要时才会将逗号插入到单独的索引中，例如 $a_{2,3j}$ 和 ${[A]}_{2i-1, 3}$；

- 矩阵转置（transpose）：
    - 当交换矩阵的行和列时，结果称为矩阵的转置（transpose）。通常用 $\mathbf{X}^\top$ 来表示矩阵的转置，如果 $\mathbf{B}=\mathbf{A}^\top$，则对于任意 $i$ 和 $j$，都有 $b_{ij}=a_{ji}$；
    $$
    \mathbf{A}^{\mathsf{T}}={\left[\begin{array}{c c c c}
        {a_{11}} & {a_{21}} & {\cdots} & {a_{m1}}\\
        {a_{12}} & {a_{22}} & {\cdots} & {a_{m2}}\\
        {\vdots} & {\vdots} & {\ddots} & {\vdots}\\
        {a_{1n}} & {a_{2n}} & {\cdots} & {a_{m n}}
    \end{array}\right]}
    $$

- 对称矩阵（symmetric matrix）：作为方阵的一种特殊类型，对称矩阵 $\mathbf{A}$ 等于其转置：$\mathbf{A}=\mathbf{A}^\top$；
- 张量（tensor）：
    - 就像 向量 是 标量 的推广，矩阵 是 向量 的推广一样，可构建具有更多轴的数据结构。张量（指代数对象）是描述具有任意数量轴的 $n$ 维数组的通用方法。例如，向量 是一阶张量，矩阵 是二阶张量。张量用无衬线大写字母表示，如 $\mathsf{X}$、$\mathsf{Y}$ 和 $\mathsf{Z}$；
    - 张量的索引机制与矩阵类似（如 $x_{ijk}$ 和 ${[\mathsf{X}]}_{1,2i-1,3}$）；
- 哈达玛积（Hadamard product）：两个矩阵的按元素乘法称为 $Hadamard$ 积，用数学符号 $\odot$ 表示。对于矩阵 $\mathbf{A} \in \mathbb{R}^{m \times n}$ 和矩阵 $\mathbf{B} \in \mathbb{R}^{m \times n}$，其中第 $i$ 行和第 $j$ 列的元素分别是是 $a_{ij}$ 和 $b_{ij}$，则 $\mathbf{A}$ 和 $\mathbf{B}$ 的 Hadamard 积为：
    $$
    \mathbf{A} \odot \mathbf{B}=\left[\begin{array}{c c c c}
        {{a_{11}b_{11}}} & {{a_{12}b_{12}}} & {{\cdots}} & {{a_{1n}b_{1n}}}\\
        {{a_{21}b_{21}}} & {{a_{22}b_{22}}} & {{\cdots}} & {{a_{2n}b_{2n}}}\\
        {{\vdots}} & {{\vdots}} & {{\ddots}} & {{\vdots}}\\
        {{a_{m1}b_{m1}}} & {{a_{m2}b_{m2}}} & {{\cdots}} & {{a_{m n}b_{m n}}}
    \end{array}\right]
    $$
- 点积（dot product）：给定两个向量 $\mathbf{x}, \mathbf{y} \in \mathbb{R}^{d}$，它们的点积（dot product） $\mathbf{x}^\top\mathbf{y}$（或 $\left\langle \mathbf{x},\mathbf{y} \right\rangle$）是相同位置的按元素乘积的和：$\mathbf{x}^\top\mathbf{y}=\sum\limits_{i=1}^{d}x_i y_i$；

---

矩阵-向量积（matrix-vector product）：对于矩阵 $\mathbf{A} \in \mathbb{R}^{m \times n}$ 和 向量 $\mathbf{x} \in \mathbb{R}^{n}$，将矩阵 $\mathbf{A}$ 用其行向量表示：
$$
\mathbf{A} = \left[\begin{array}{c}
    \mathbf{a}_1^\top \\
    \mathbf{a}_2^\top \\
    \vdots \\
    \mathbf{a}_m^\top
\end{array}\right],
$$
其中每个 $a_{i}^\top \in \mathbb{R}^{n}$ 都是行向量，表示矩阵的第 $i$ 行。矩阵向量积 $\mathbf{A}\mathbf{x}$ 是一个长度为 $m$ 的列向量，其第 $i$ 个元素是点积 $a_{i}^\top \mathbf{x}$：
$$
{\mathbf{A}}{\mathbf{x}}=\left[\begin{array}{c}
    {\mathbf{a}}_{1}^{\top}\\
    {\mathbf{a}}_{2}^{\top}\\
    \vdots\\
    {\mathbf{a}}_{m}^{\top}
\end{array}\right]

\ \ \ \

{\mathbf{x}}=\left[\begin{array}{c}
    {\mathbf{a}}_{1}^{\top}{\mathbf{x}}\\
    {\mathbf{a}}_{2}^{\top}{\mathbf{x}}\\
    \vdots\\
    {\mathbf{a}}_{m}^{\top}{\mathbf{x}}
\end{array}\right]
$$

------

矩阵-矩阵乘法（matrix-matrix multiplication）：假设有两个矩阵 $\mathbf{A} \in \mathbb{R}^{n \times k}$ 和 $\mathbf{B} \in \mathbb{R}^{k \times m}$：

$$
\mathbf{A}={\left[\begin{array}{c c c c}
    {a_{11}} & {a_{12}} & {\cdots} & {a_{1k}}\\
    {a_{21}} & {a_{22}} & {\cdots} & {a_{2k}}\\
    {\vdots} & {\vdots} & {\ddots} & {\vdots}\\
    {a_{n1}} & {a_{n2}} & {\cdots} & {a_{n k}}
\end{array}\right]},
\ \ \ \
\mathbf{B}=\left[{\begin{array}{c c c c}
    {b_{11}} & {b_{12}} & {\cdots} & {b_{1m}}\\
    {b_{21}} & {b_{22}} & {\cdots} & {b_{2m}}\\
    {\vdots} & {\vdots} & {\ddots} & {\vdots}\\
    {b_{k1}} & {b_{k2}} & {\cdots} & {b_{k m}}
\end{array}}\right]
$$

用行向量 $\mathbf{a}_{i}^\top \in \mathbb{R}^{k}$ 表示矩阵 $\mathbf{A}$ 的第 $i$ 行，并让列向量 $\mathbf{b}_{j} \in \mathbb{R}^{k}$ 作为矩阵 $\mathbf{B}$ 的第 $j$ 列。要生成矩阵积 $\mathbf{C} = \mathbf{A}\mathbf{B}$，最简单的方法是考虑 $\mathbf{A}$ 的行向量和 $\mathbf{B}$ 的列向量：

$$
\mathbf{A}=\left[\begin{array}{c}
    \mathbf{a}_{1}^\top \\
    \mathbf{a}_{2}^\top \\
    \vdots \\
    \mathbf{a}_{1}^\top \\
\end{array}\right],
\ \ \ \
\mathbf{B}=\left[\begin{array}{c c c c}
    \mathbf{b}_{1} & \mathbf{b}_{2} & \cdots & \mathbf{b}_{m}
\end{array}\right]
$$

简单地将每个元素 $c_{ij}$ 计算为点积 $\mathbf{a}_{i}^\top \mathbf{b}_{j}$：
$$
\mathbf{C}=\mathbf{A}\mathbf{B}=\left[\begin{array}{c}
    \mathbf{a}_{1}^{\top}\\
    \mathbf{a}_{2}^{\top}\\
    \vdots\\
    \mathbf{a}_{n}^{\top}
\end{array}\right]
\left[\begin{array}{c c c c}
    \mathbf{b}_{1} & \mathbf{b}_{2} & \cdots & \mathbf{b}_{m}
\end{array}\right]
=\left[\begin{array}{c c c c}
    \mathbf{a}_{1}^{\top}\mathbf{b}_{1} & \mathbf{a}_{1}^{\top}\mathbf{b}_{2} & \cdots & \mathbf{a}_{1}^{ \top}\mathbf{b}_{m}\\
    \mathbf{a}_{2}^{\top}\mathbf{b}_{1} & \mathbf{a}_{2}^{\top}\mathbf{b}_{2} & \cdots & \mathbf{a}_{2}^{\top}\mathbf{b}_{m}\\
    \vdots & \vdots & \ddots & \vdots\\
    \mathbf{a}_{n}^{\top}\mathbf{b}_{1} & \mathbf{a}_{n}^{\top}\mathbf{b}_{2} & \cdots & \mathbf{a}_{n}^{\top}\mathbf{b}_{m}
\end{array}\right]
$$

可以将矩阵-矩阵乘法 $\mathbf{A}\mathbf{B}$ 看作简单地执行 $m$ 次矩阵-向量积，并将结果拼接在一起，形成一个 $n \times m$ 矩阵；

------

范数（norm）：
- 向量的范数表示一个向量有多大，这里考虑的大小（size）概率不涉及维度，而是分量的大小。范数是线性代数中最有用的一些运算符；
- 向量范数：将向量映射到标量的函数 $f$。
    - 给定任意向量 $\mathbf{x}$，向量范数要满足一些性质：
        1. 如果按常数因子 $\alpha$ 缩放向量的所有元素，其范数也会按相同常数因子的绝对值缩放：$f(\alpha\mathbf{x})=|\alpha|f(\mathbf{x})$；
        2. 三角不等式：$f(\mathbf{x} + \mathbf{y}) \leq f(\mathbf{x}) + f(\mathbf{y})$；
        3. 范数必须是非负的：$f(\mathbf{x}) \geq 0$；（这是有道理的，因为在大多数情况下，任何东西的最小大小都是 $0$）
        4. 范数最小为 $0$，当且仅当向量全由 $0$ 组成：$\forall i, {[\mathbf{x}]}_{i} = 0 \Leftrightarrow f(\mathbf{x})=0$；
- $L_{2}$ 范数：
    - 假设 $n$ 维向量 $\mathbf{x}$ 中的元素是 $x_1, x_2, \dots, x_n$，其 $L_{2}$ 范数是向量元素平方和的平方根：${\parallel \mathbf{x} \parallel}_{2}=\sqrt{\sum\limits_{i=1}^{n} x_{i}^{2}}$；
    - 其中 $L_{2}$ 范数中常常省略下标 $2$，即 ${\parallel \mathbf{x} \parallel}$ 等同于 ${\parallel \mathbf{x} \parallel}_{2}$；
    - 事实上，欧几里得距离是一个 $L_{2}$ 范数；
- $L_{1}$ 范数：
    - 深度学习中更经常地使用 $L_{2}$ 范数的平方，也会经常遇到 $L_{1}$ 范数，它表示为向量元素的绝对值之和：${\parallel \mathbf{x} \parallel}_{1}=\sum\limits_{i=1}^{n}|x_i|$；
    - 与 $L_{2}$ 范数相比，$L_1$ 范数受异常值的影响较小；
- $L_{p}$ 范数：
    - $L_{2}$范数 和 $L_{1}$范数 都是更一般的 $L_{p}$范数 的特例：${\parallel \mathbf{x} \parallel}_{p}={(\sum\limits_{i=1}^{n} {|x_i|}^{p})}^{1/p}$；
- 弗罗贝尼乌斯范数（Frobenius 范数，Frobenius norm）：
    - 矩阵 $\mathbf{X} \in \mathbb{R}^{m \times n}$ 的 Frobenius 范数是矩阵元素平方和的平方根：${\parallel \mathbf{X} \parallel}_{F}=\sqrt{\sum\limits_{i=1}^{m} \sum\limits_{j=1}^{n} x_{ij}^{2}}$；
    - Frobenius 范数满足向量范数的所有性质，其就像是矩阵形向量的 $L_{2}$范数；

**范数和目标**：
- 深度学习中，通常试图解决优化问题：最大化分配给观测数据的概率；最小化预测和真实观测之间的距离；
- 用向量表示对象（如单词、产品等），以便最小化相似项目之间的距离，最大化不同项目之间的距离；
- 目标，或许是深度学习算法最重要的组成部分（除开数据），通常被表达为范数；

------

## 微积分

微积分的两大分支：
1. 积分（integral calculus）；
2. 微分（differential calculus）；

- 逼近法（method of exhaustion）：
    - 古希腊人通过内接多边形来估算圆面积，内接多边形等长边越多，就越接近圆，该过程被称为“逼近法”；
    - 逼近法就是积分（integral calculus）的起源；

微分学最重要的应用是优化问题，即考虑如何把事情做到最好；

------

导数和微分：
- 导数：
    - 假设有一个函数 $f: \mathbb{R} \to \mathbb{R}$，其输入和输出都是标量。如果 $f$ 的导数存在，则这个极限被定义为：
        $$
        f^{\prime}(x)=\lim_{h\to0}{\frac{f(x+h)-f(x)}{h}}
        $$
    - 可将导数 $f^{\prime}(x)$ 解释为 $f(x)$ 相对于 $x$ 的瞬时（instantaneous）变化率，即基于 $x$ 中的变化 $h$，且 $h$ 接近 $0$；
    - 导数的几个等效符号：给定 $y=f(x)$，其中 $x$ 和 $y$ 分别是函数 $f$ 的自变量和因变量，下述表达式等效：
        $$
        f^{\prime}(x)=y^{\prime}={\frac{d y}{d x}}={\frac{d f}{d x}}={\frac{d}{d x}}f(x)=D f(x)=D_{x}f(x)
        $$
        - 其中符号 $\frac{d}{d x}$ 和 $D$ 是微分运算符，表示微分操作；
- 可微（differentiable）：
    - 如果 $f^{\prime}(x)$ 存在，则称 $f$ 在 $a$ 处是可微的。如果 $f$ 在一个区间内的每个数上都是可微的，则此函数在此区间中是可微的；
- 微分规则：
    - 可使用以下规则对常见函数求微分：
        - $D C = 0$（$C$ 是一个常数）；
        - $D x^{n} = n x^{n-1}$；（幂律（power rule），$n$ 是任意实数）
        - $D e^x = e^x$；
        - $D \ln(x) = 1 / x$；
    - 微分复合函数的法则：假设函数 $f$ 和 $g$ 都是可微的，$C$ 是一个常数：
        - 常数相乘法则：$\frac{d}{d x}[C f(x)]=C\frac{d}{d x}f(x)$；
        - 加法法则：${\frac{d}{d x}}[f(x)+g(x)]={\frac{d}{d x}}f(x)+{\frac{d}{d x}}g(x)$；
        - 乘法法则：${\frac{d}{d x}}[f(x)g(x)]=f(x){\frac{d}{d x}}[g(x)]+g(x){\frac{d}{d x}}[f(x)]$；
        - 除法法则：$\frac{d}{d x}\left[\frac{f(x)}{g(x)}\right]=\frac{g(x)\frac{d}{d x}[f(x)]-f(x)\frac{d}{d x}[g(x)]}{[g(x)]^{2}}$；

------

偏导数（partial derivative）：
- 目前为止仅讨论了含一个变量的函数的微分，需要将微分的思想推广到多元函数（multivariate function）上；
- 设 $y=f(x_1, x_2, \ldots, x_n)$ 是一个具有 $n$ 个变量的函数。$y$ 关于第 $i$ 个参数 $x_i$ 的偏导数为：
    $$
    {\frac{\partial y}{\partial x_{i}}}=
    \lim_{h\to0}{\frac{f(x_{1},\ldots,x_{i-1},x_{i}+h,x_{i+1},\ldots,x_{n})-f(x_{1},\ldots,x_{i},\ldots,x_{n})}{h}}
    $$
    - 为计算 $\frac{\partial y}{\partial x_{i}}$，可简单地将 $x_{1},\ldots,x_{i-1},x_{i}+h,x_{i+1},\ldots,x_{n}$ 看作常数，并计算 $y$ 关于 $x_{i}$ 的导数；
- 对于偏导数的表示，以下是等价的：
    $$
    {\frac{\partial y}{\partial x_{i}}}={\frac{\partial f}{\partial x_{i}}}=f_{x_{i}}=f_{i}=D_{i}f=D_{x_{i}}f
    $$

------

梯度（gradient）：
- 可以连结一个多元函数对其所有变量的偏导数，以得到该函数的梯度向量；
- 设函数 $f: \mathbb{R}^{n} \to \mathbb{R}$ 的输入是一个 $n$ 维向量 $\mathbf{x}={\left[ x_1, x_2, \ldots, x_n \right]}^\top$，并且输出是一个标量。函数 $f(\mathbf{x})$ 相对于 $\mathbf{x}$ 的梯度是一个包含 $n$ 个偏导数的向量：
    $$
    \nabla_{\mathbf{x}}f(\mathbf{x})=
    {\left[
        {\frac{\partial f(\mathbf{x})}{\partial x_{1}}},
        {\frac{\partial f(\mathbf{x})}{\partial x_{2}}},
        \ldots,
        {\frac{\partial f(\mathbf{x})}{\partial x_{n}}}
    \right]}^{\top}
    $$
    - 其中 $\nabla_{\mathbf{x}}$ 通常在没有歧义时被 $\nabla f(\mathbf{x})$ 取代；
- 假设 $\mathbf{x}$ 为 $n$ 维向量，在微分多元函数时经常使用以下规则：
    - 对于所有 $\mathbf{A} \in \mathbb{R}^{m \times n}$，都有 $\nabla_{\mathbf{x}} \mathbf{A}\mathbf{x} = \mathbf{A}^\top$；
    - 对于所有 $\mathbf{A} \in \mathbb{R}^{m \times n}$，都有 $\nabla_{\mathbf{x}} \mathbf{x}^\top \mathbf{A} = \mathbf{A}$
    - 对于所有 $\mathbf{A} \in \mathbb{R}^{m \times n}$，都有 $\nabla_{\mathbf{x}} \mathbf{x}^\top \mathbf{A} \mathbf{x} = (\mathbf{A} + \mathbf{A}^\top)\mathbf{x}$；
    - $\nabla_{\mathbf{x}} {\parallel \mathbf{x} \parallel}^{2} = \nabla_{\mathbf{x}} \mathbf{x}^\top \mathbf{x} = 2\mathbf{x}$；
    - 对于任何矩阵 $\mathbf{X}$，都有 $\nabla_{\mathbf{X}} {\parallel \mathbf{X} \parallel}_{F}^{2} = 2 \mathbf{X}$；

------

链式法则：可用于微分复合函数；
- 首先考虑单变量函数。假设函数 $y=f(x)$ 和 $u=g(x)$ 都是可微的，根据链式法则：$\frac{d y}{d x} = \frac{d y}{d u} \frac{d u}{d x}$；
- 考虑一个更一般的场景，即函数具有任意数量的变量的情况。假设可微分函数 $y$ 有变量 $u_1, u_2, \ldots, u_m$，其中每个可微分函数 $u_i$ 都有变量 $x_1, x_2, \ldots, x_n$。注意，$y$ 是 $x_1, x_2, \ldots, x_n$ 的函数，对于任意的 $i=1, 2, \ldots, n$，链式法则给出：
    $$
    {\frac{\partial y}{\partial x_{i}}}=
        {\frac{\partial y}{\partial u_{1}}} {\frac{\partial u_{1}}{\partial x_{i}}} +
        {\frac{\partial y}{\partial u_{2}}} {\frac{\partial u_{2}}{\partial x_{i}}} +
        \cdots +
        {\frac{\partial y}{\partial u_{m}}} {\frac{\partial u_{m}}{\partial x_{i}}}
    $$

------

## 概率

- 抽样（sampling）：在统计学中，把从概率分布中抽取样本的过程称为“抽样”；
- 分布（distribution）：笼统来说，可以把分布看作对事件的概率分配；
    - 多项分布（multinomial distribution）：将概率分配给一些离散选择的分布称为“多项分布”；
- 样本空间（sample space）；
- 结果空间（outcome space）；
- 结果（outcome）；
- 事件（event）：一组给定样本空间的随机结果；（如果一个随机实验的结果在 $\mathcal{A}$ 中，则事件 $\mathcal{A}$ 已经发生）

------

概率（probability）：
- 概率可以被认为是将集合映射到真实值的函数。在给定的样本空间 $\mathcal{S}$ 中，事件 $\mathcal{A}$ 的概率，表示为 $P(\mathcal{A})$；
- 概率论公理/概率属性：
    - 对于任意事件 $\mathcal{A}$，其概率从不会是负数，即 $P(\mathcal{A}) \geq 0$；
    - 整个样本空间的概率为 $1$，即 $P(\mathcal{S}) = 1$；
    - 对于互斥（mutually exclusive）事件（对于所有 $i \neq j$ 都有 $\mathcal{A}_{i} \cap \mathcal{A}_{j} = \emptyset$）的任意一个可数序列 $\mathcal{A}_{1}, \mathcal{A}_{2}, \ldots$，序列中任意一个事件发生的概率等于它们各自发生的概率之和，即 $P(\bigcup_{i=1}^{\infty} \mathcal{A}_{i}) = \sum_{i=1}^{\infty} P(\mathcal{A}_i)$；
- 以上概率论公理，由科尔莫戈罗夫于 1993 年提出。有了这个公理系统，就可以避免任何关于随机性的哲学争论；相反，可以用数学语言严格地推理；

------

随机变量（random variable）：
- 随机变量几乎可以是任何数量，并且它可以在随机实验的一组可能性中取一个值。通过 $P(X=a)$，可以区分随机变量 $X$ 和 $X$ 可以采取的值（例如 $a$）；
- 为简化符号，一方面，可以将 $P(X)$ 表示为随机变量 $X$ 上的分布（distribution）：分布告诉我们 $X$ 获得某一值的概率。另一方面，我们可以简单用 $P(a)$ 表示随机变量取值 $a$ 的概率；
- 由于概率论中的事件是来自样本空间的一组结果，因此可以为随机变量指定值的可取范围；（如 $P(1\leq X\leq 3)$）
- 离散（discrete）随机变量 和 连续（continuous）随机变量之间存在微妙的区别；
    - 在某些情况下，将看到某个数值的可能性量化为密度（density）；
    - 实际应用中，一般考虑离散空间中的概率

------

处理多个随机变量：
- 很多时候，会考虑多个随机变量，需要估计这些概率以及概率之间的关系；多变量常见联合发生的随机变量，当处理多个随机变量时，会有若干变量是我们感兴趣的；

------

联合概率（joint probability）：
- 给定任意值 $a$ 和 $b$，联合概率 $P(A=a, B=b)$ 可以回答：$A=a$ 和 $B=b$ 同时满足的概率是多少；
- 对于任何 $a$ 和 $b$ 的取值，$P(A=a, B=b) \leq P(A=a)$；

条件概率（conditional probability）：
- 联合概率的不等式可导出：$0\leq \frac{P(A=a, B=b)}{P(A=a)}\leq 1$，称这个比率为条件概率；
- 条件概率使用 $P(B=b \mid A=a)$ 表示：当 $A=a$ 发生的前提下，$B=b$ 的概率；

贝叶斯定理（Bayes' theorem）：
- 使用条件概率的定义，可得出统计学中最有用的方程之一：Bayes定理；
- 推导过程：
    - 根据乘法法则（multiplication rule）可得到：$P(A,B)=P(B\mid A)P(A)$；
    - 根据对称性，可得到：$P(A,B)=P(A\mid B)P(B)$；
    - 假设 $P(B) > 0$，求解其中一个条件变量，可得到：$P(A\mid B) = \frac{P(B\mid A)P(A)}{P(B)}$；
- 注意，使用紧凑的表示法：其中 $P(A,B)$ 是一个联合分布，$P(A\mid B)$ 是一个条件分布；

边际化：
- 为了能进行事件概率求和，我们需要求和法则（sum rule），即 $B$ 的概率相当于计算 $A$ 的所有可能选择，并将所有选择的联合概率聚合在一起：$P(B) = \sum\limits_{A} P(A,B)$；
- 这也称为边际化（marginalization）。边际化结果的概率或分布称为 边际概率（marginal probability）或 边际分布（marginal distribution）；

独立性：
- 另一个有用属性是 依赖（dependence）与 独立（independence）；
    - 如果两个随即变量 $A$ 和 $B$ 是独立的，意味着事件 $A$ 的发生跟 $B$ 事件的发生无关。在这种情况下，统计学家通常将这一点表述为 $A \perp B$。根据贝叶斯定理，马上就能同样得到 $P(A \mid B) = P(A)$；
    - 在所有其他情况下，称 $A$ 和 $B$ 依赖；
- 由于 $P(A\mid B)=\frac{P(A,B)}{P(B)}=P(A)$ 等价于 $P(A,B)=P(A)P(B)$，因此两个随机变量是独立的，当且仅当两个随机变量的联合分布是其各自分布的乘积；
- 给定另一随机变量 $C$ 时，两个随机变量 $A$ 和 $B$ 是条件独立的（conditionally independent），当且仅当 $P(A,B \mid C) = P(A \mid C) P(B \mid C)$，这个情况表示为 $A \perp B \mid C$；

------

为了概括概率分布的关键特征，我们需要一些测量方法；

期望：
- 一个随机变量 $X$ 的期望（expectation，或平均值（average））表示为：$E[X] = \sum\limits_{x} x P(X=x)$；
- 当函数 $f(x)$ 的输入是从分布 $P$ 中抽取的随机变量时，$f(x)$ 的期望值为：$E_{x \sim P}[f(x)] = \sum\limits_{x} f(x) P(x)$；

方差：
- 在许多情况下，希望衡量随机变量 $X$ 与其期望值的偏置，这可以通过方差来量化：$\operatorname{Var}[X] = E[{(X - E[X])}^{2}] = E[X^{2}] - {E[X]}^{2}$；
- 方差的平方根被称为标准差（standard deviation）；
- 随机变量函数的方差衡量的是：当从该随机变量分布中采样不同值 $x$ 时，函数值偏离该函数的期望的程度：$\operatorname{Var}[f(x)] = E[{(f(x) - E[f(x)])}^{2}]$；

------

概率密度函数（Probability Density Function，简称PDF）是描述连续型随机变量在某个确定取值点附近的可能性的函数。它是累积分布函数的导数，用于表示随机变量在某个区间内取值的概率。

自然数e：
- https://www.bilibili.com/video/BV1t3411p7Kn/?spm_id_from=333.337.search-card.all.click&vd_source=2a11f9f700546028a49b63c0d54f4bda
- https://zhuanlan.zhihu.com/p/114266598
- https://zh.wikipedia.org/wiki/E_(%E6%95%B0%E5%AD%A6%E5%B8%B8%E6%95%B0)



## 其它

- $f: \mathbb{R} \to \mathbb{R}$：一元标量运算符（直接收一个输入）。意味着该函数从任何实数（$\mathbb{R}$）映射到另一个实数；
- $f: \mathbb{R}, \mathbb{R} \to \mathbb{R}$：二元标量运算符。意味着该函数接收两个输入，并产生一个输出；
- $F: \mathbb{R}^d, \mathbb{R}^d \to \mathbb{R}^d$：按元素向量运算符。给定向量 $\mathbf{u}$ 和 $\mathbf{v}$ 以及二元运算符号 $f$，可构建向量 $\mathbf{c} = F(\mathbf{u}, \mathbf{v})$，具体计算方法为 $c_i \leftarrow f(u_i, v_i)$，其中 $c_i$、$u_i$ 和 $v_i$ 分别是向量 $\mathbf{c}$、$\mathbf{u}$ 和 $\mathbf{v}$ 中的元素；









