# 数学符号规范

## 数字

- $x$：标量；
- $\mathbf{x}$：向量；
- $\mathbf{X}$：矩阵；
- $\mathsf{X}$：张量；
- $\mathbf{I}$：单位矩阵；
- $x_i, {[x]}_i$：向量 $\mathbf{x}$ 第 $i$ 个元素；
- $x_{ij}, {[\mathbf{X}]}_{ij}$：矩阵 $\mathbf{x}$ 第 $i$ 行第 $j$ 列的元素；

## 集合论

- $\mathcal{X}$：集合；
- $\mathbb{Z}$：整数集合；
- $\mathbb{R}$：实数集合；
- $\mathbb{R}^n$：$n$ 维实数向量集合；
- $\mathbb{R}^{a\times b}$：包含 $a$ 行和 $b$ 列的实数矩阵集合；
- $\mathcal{A}\cup \mathcal{B}$：集合 $\mathcal{A}$ 和 $\mathcal{B}$ 的并集；
- ${\mathcal{A}}\cap{\mathcal{B}}$：集合 $\mathcal{A}$ 和 $\mathcal{B}$ 的交集；
- ${\mathcal{A}} \setminus {\mathcal{B}}$：集合 $\mathcal{A}$ 与 $\mathcal{B}$ 相减，$\mathcal{B}$ 关于 $\mathcal{A}$ 的相对补集；

## 函数和运算符

- $f(\cdot)$：函数；
- $\log(\cdot)$：自然对数；
- $\exp(\cdot)$：指数函数；
- $\mathbf{1}_{\mathcal{X}}$：指示函数；
- ${(\cdot)}^\top$：向量或矩阵的转置；
- $\mathbf{X}^{-1}$：矩阵的逆；
- $\odot$：按元素相乘；
- $[\cdot,\cdot]$：连结；
- $|\mathcal{X}|$：集合的基数；
- ${\parallel\cdot\parallel}_p$​：$L_p$ 正则；
- $\parallel\cdot\parallel$：$L_2$ 正则；
- $\left\langle\mathbf{x},\mathbf{y}\right\rangle$：向量 $\mathbf{x}$ 和 $\mathbf{y}$ 的点积；
- $\sum$：连加；
- $\prod$：连乘；
- $\stackrel{\mathrm{def}}{=}$：定义；

## 微积分

- $\frac{d y}{d x}$：$y$ 关于 $x$ 的导数；
- $\frac{\partial y}{\partial x}$：$y$ 关于 $x$ 的偏导数；
- $\nabla_{x}y$：$y$ 关于 $\mathbf{x}$ 的梯度；
- $\int_{a}^{b} f(x)\ dx$：$f$ 在 $a$ 到 $b$ 区间上关于 $x$ 的定积分；
- $\int f(x)\ dx$：$f$ 关于 $x$ 的不定积分；

## 概率与信息论

- $P(\cdot)$：概率分布；
- $z \sim P$：随机变量 $z$ 具有概率分布 $P$；
- $P(X \mid Y)$：$X \mid Y$ 的条件概率；
- $p(x)$：概率密度函数；
- $E_{x}[f(x)]$：函数 $f$ 对 $x$ 的数学期望；
- $X \perp Y$：随机变量 $X$ 和 $Y$ 是独立的；
- $X \perp Y \mid Z$：随机变量 $X$ 和 $Y$ 在给定随机变量 $Z$ 的条件下是独立的；
- $\mathrm{Var}(X)$：随机变量 $X$ 的方差；
- $\sigma_{X}$：随机变量 $X$ 的标准差；
- $\mathrm{Cov}(X,Y)$：随机变量 $X$ 和 $Y$ 的协方差；
- $\rho(X,Y)$：随机变量 $X$ 和 $Y$ 的相关性；
- $H(X)$：随机变量 $X$ 的熵；
- $D_{\mathrm{KL}}(P\parallel Q)$：$P$ 和 $Q$ 的 KL-散度；

## 复杂度

- $\mathcal{O}$：大 $O$ 标记；



# 数学定义

## 线性代数

- 标量（scalar）：仅包含一个数值。一般采用普通小写字母表示，如 $x$、$y$ 和 $z$；

- 变量（variable）：表示未知的数值（标量/张量）；

- 空间（space）：如用 $\mathbb{R}$ 表示所有（连续）实数标量的空间；

- 符号 $\in$ 称为“属于”，其表示 “是集合中的成员”，例如 $x, y \in \{0, 1\}$ 可用于表明 $x$ 和 $y$ 是值只能为 $0$ 或 $1$ 的数字，表达式 $x \in \mathbb{R}$ 是表示 $x$ 是一个实值标量的正式形式；

- 向量（vector）：
    - 由标量值组成的列表，这些标量值被称为向量的 元素（element）/ 分量（component）。数学表示法中，向量通常记为粗体、小写的符号，如 $\mathbf{x}$、$\mathbf{y}$ 和 $\mathbf{z}$；
    - 大量文献认为，列向量是向量的默认方向。在数学中，向量 $\mathbf{x}$ 可写成如下形式，其中 $x_1, \dots, x_n$ 是向量的元素；
        $$
        \mathbf{x}={\left[\begin{array}{c}
            {x_{1}}\\ {x_{2}}\\ {\vdots}\\ {x_{n}}\end{array}
        \right]}
        $$

    - 向量只是一个数字数组，就像每个数组都有一个长度一样，每个向量也是如此。在数学表示法中，如果我们想说一个向量 $\mathbf{x}$ 由 $n$ 个实值标量组成，可将其表示为 $\mathbf{x} \in \mathbb{R}^{n}$。向量的长度通常称为 向量的维度（dimension）；
    - 区分：
        - 向量/轴 的维度被用来表示 向量/轴 的长度，即 向量/轴 的元素数量；
        - 张量 的维度被用来表示 张量 具有的轴数，即张量的某个轴的维数就是这个轴的长度；

- 矩阵（matrix）：

    - 正如 向量 将 标量 从零阶推广到一阶，矩阵 将 向量 从一阶推广到二阶。矩阵等价于具有两个轴的张量/二维张量，通常用粗体、大写字母来表示，如 $\mathbf{X}$、$\mathbf{Y}$ 和 $\mathbf{Z}$；
    - 数学表示法使用 $\mathbf{A} \in \mathbb{R}^{m \times n}$ 来表示矩阵 $\mathbf{A}$，其由 $m$ 行和 $n$ 列的实值标量组成。可将任意矩阵 $\mathbf{A} \in \mathbb{R}^{m \times n}$ 视为一个表格，其中每个元素 $a_{ij}$ 属于第 $i$ 行第 $j$ 列：
    $$
    \mathbf{A}={\left[\begin{array}{c c c c}
        {a_{11}} & {a_{12}} & {\cdots} & {a_{1n}}\\
        {a_{21}} & {a_{22}} & {\cdots} & {a_{2n}}\\
        {\vdots} & {\vdots} & {\ddots} & {\vdots}\\
        {a_{m1}} & {a_{m2}} & {\cdots} & {a_{m n}}
    \end{array}\right]}
    $$
    - 对于任意 $\mathbf{A} \in \mathbb{R}^{m \times n}$，$\mathbf{A}$ 的形状是 $(m,n)$ 或 $m \times n$。当矩阵具有相同数量的行和列时，其形状将变为正方形；因此，它被称为方阵（square matrix）；
    - 可通过 行索引 $(i)$ 和 列索引 $(j)$ 来访问矩阵中的标量元素 $a_{ij}$，例如 ${[\mathbf{A}]}_{ij}$。若未给出矩阵 $\mathbf{A}$ 的标量元素，则可简单地使用矩阵 $\mathbf{A}$ 的小写字母索引下标 $a_{ij}$ 来引用 ${[\mathbf{A}]}_{ij}$。为了表示起来简单，只有在必要时才会将逗号插入到单独的索引中，例如 $a_{2,3j}$ 和 ${[A]}_{2i-1, 3}$；

- 矩阵转置（transpose）：
    - 当交换矩阵的行和列时，结果称为矩阵的转置（transpose）。通常用 $\mathbf{X}^\top$ 来表示矩阵的转置，如果 $\mathbf{B}=\mathbf{A}^\top$，则对于任意 $i$ 和 $j$，都有 $b_{ij}=a_{ji}$；
    $$
    \mathbf{A}^{\mathsf{T}}={\left[\begin{array}{c c c c}
        {a_{11}} & {a_{21}} & {\cdots} & {a_{m1}}\\
        {a_{12}} & {a_{22}} & {\cdots} & {a_{m2}}\\
        {\vdots} & {\vdots} & {\ddots} & {\vdots}\\
        {a_{1n}} & {a_{2n}} & {\cdots} & {a_{m n}}
    \end{array}\right]}
    $$

- 对称矩阵（symmetric matrix）：作为方阵的一种特殊类型，对称矩阵 $\mathbf{A}$ 等于其转置：$\mathbf{A}=\mathbf{A}^\top$；
- 张量（tensor）：
    - 就像 向量 是 标量 的推广，矩阵 是 向量 的推广一样，可构建具有更多轴的数据结构。张量（指代数对象）是描述具有任意数量轴的 $n$ 维数组的通用方法。例如，向量 是一阶张量，矩阵 是二阶张量。张量用无衬线大写字母表示，如 $\mathsf{X}$、$\mathsf{Y}$ 和 $\mathsf{Z}$；
    - 张量的索引机制与矩阵类似（如 $x_{ijk}$ 和 ${[\mathsf{X}]}_{1,2i-1,3}$）；
- 哈达玛积（Hadamard product）：两个矩阵的按元素乘法称为 $Hadamard$ 积，用数学符号 $\odot$ 表示。对于矩阵 $\mathbf{A} \in \mathbb{R}^{m \times n}$ 和矩阵 $\mathbf{B} \in \mathbb{R}^{m \times n}$，其中第 $i$ 行和第 $j$ 列的元素分别是是 $a_{ij}$ 和 $b_{ij}$，则 $\mathbf{A}$ 和 $\mathbf{B}$ 的 Hadamard 积为：
    $$
    \mathbf{A} \odot \mathbf{B}=\left[\begin{array}{c c c c}
        {{a_{11}b_{11}}} & {{a_{12}b_{12}}} & {{\cdots}} & {{a_{1n}b_{1n}}}\\
        {{a_{21}b_{21}}} & {{a_{22}b_{22}}} & {{\cdots}} & {{a_{2n}b_{2n}}}\\
        {{\vdots}} & {{\vdots}} & {{\ddots}} & {{\vdots}}\\
        {{a_{m1}b_{m1}}} & {{a_{m2}b_{m2}}} & {{\cdots}} & {{a_{m n}b_{m n}}}
    \end{array}\right]
    $$
- 点积（dot product）：给定两个向量 $\mathbf{x}, \mathbf{y} \in \mathbb{R}^{d}$，它们的点积（dot product） $\mathbf{x}^\top\mathbf{y}$（或 $\left\langle \mathbf{x},\mathbf{y} \right\rangle$）是相同位置的按元素乘积的和：$\mathbf{x}^\top\mathbf{y}=\sum\limits_{i=1}^{d}x_i y_i$；

---

矩阵-向量积（matrix-vector product）：对于矩阵 $\mathbf{A} \in \mathbb{R}^{m \times n}$ 和 向量 $\mathbf{x} \in \mathbb{R}^{n}$，将矩阵 $\mathbf{A}$ 用其行向量表示：
$$
\mathbf{A} = \left[\begin{array}{c}
    \mathbf{a}_1^\top \\
    \mathbf{a}_2^\top \\
    \vdots \\
    \mathbf{a}_m^\top
\end{array}\right],
$$
其中每个 $a_{i}^\top \in \mathbb{R}^{n}$ 都是行向量，表示矩阵的第 $i$ 行。矩阵向量积 $\mathbf{A}\mathbf{x}$ 是一个长度为 $m$ 的列向量，其第 $i$ 个元素是点积 $a_{i}^\top \mathbf{x}$：
$$
{\mathbf{A}}{\mathbf{x}}=\left[\begin{array}{c}
    {\mathbf{a}}_{1}^{\top}\\
    {\mathbf{a}}_{2}^{\top}\\
    \vdots\\
    {\mathbf{a}}_{m}^{\top}
\end{array}\right]

\ \ \ \

{\mathbf{x}}=\left[\begin{array}{c}
    {\mathbf{a}}_{1}^{\top}{\mathbf{x}}\\
    {\mathbf{a}}_{2}^{\top}{\mathbf{x}}\\
    \vdots\\
    {\mathbf{a}}_{m}^{\top}{\mathbf{x}}
\end{array}\right]
$$

------

矩阵-矩阵乘法（matrix-matrix multiplication）：假设有两个矩阵 $\mathbf{A} \in \mathbb{R}^{n \times k}$ 和 $\mathbf{B} \in \mathbb{R}^{k \times m}$：

$$
\mathbf{A}={\left[\begin{array}{c c c c}
    {a_{11}} & {a_{12}} & {\cdots} & {a_{1k}}\\
    {a_{21}} & {a_{22}} & {\cdots} & {a_{2k}}\\
    {\vdots} & {\vdots} & {\ddots} & {\vdots}\\
    {a_{n1}} & {a_{n2}} & {\cdots} & {a_{n k}}
\end{array}\right]},
\ \ \ \
\mathbf{B}=\left[{\begin{array}{c c c c}
    {b_{11}} & {b_{12}} & {\cdots} & {b_{1m}}\\
    {b_{21}} & {b_{22}} & {\cdots} & {b_{2m}}\\
    {\vdots} & {\vdots} & {\ddots} & {\vdots}\\
    {b_{k1}} & {b_{k2}} & {\cdots} & {b_{k m}}
\end{array}}\right]
$$

用行向量 $\mathbf{a}_{i}^\top \in \mathbb{R}^{k}$ 表示矩阵 $\mathbf{A}$ 的第 $i$ 行，并让列向量 $\mathbf{b}_{j} \in \mathbb{R}^{k}$ 作为矩阵 $\mathbf{B}$ 的第 $j$ 列。要生成矩阵积 $\mathbf{C} = \mathbf{A}\mathbf{B}$，最简单的方法是考虑 $\mathbf{A}$ 的行向量和 $\mathbf{B}$ 的列向量：

$$
\mathbf{A}=\left[\begin{array}{c}
    \mathbf{a}_{1}^\top \\
    \mathbf{a}_{2}^\top \\
    \vdots \\
    \mathbf{a}_{1}^\top \\
\end{array}\right],
\ \ \ \
\mathbf{B}=\left[\begin{array}{c c c c}
    \mathbf{b}_{1} & \mathbf{b}_{2} & \cdots & \mathbf{b}_{m}
\end{array}\right]
$$

简单地将每个元素 $c_{ij}$ 计算为点积 $\mathbf{a}_{i}^\top \mathbf{b}_{j}$：
$$
\mathbf{C}=\mathbf{A}\mathbf{B}=\left[\begin{array}{c}
    \mathbf{a}_{1}^{\top}\\
    \mathbf{a}_{2}^{\top}\\
    \vdots\\
    \mathbf{a}_{n}^{\top}
\end{array}\right]
\left[\begin{array}{c c c c}
    \mathbf{b}_{1} & \mathbf{b}_{2} & \cdots & \mathbf{b}_{m}
\end{array}\right]
=\left[\begin{array}{c c c c}
    \mathbf{a}_{1}^{\top}\mathbf{b}_{1} & \mathbf{a}_{1}^{\top}\mathbf{b}_{2} & \cdots & \mathbf{a}_{1}^{ \top}\mathbf{b}_{m}\\
    \mathbf{a}_{2}^{\top}\mathbf{b}_{1} & \mathbf{a}_{2}^{\top}\mathbf{b}_{2} & \cdots & \mathbf{a}_{2}^{\top}\mathbf{b}_{m}\\
    \vdots & \vdots & \ddots & \vdots\\
    \mathbf{a}_{n}^{\top}\mathbf{b}_{1} & \mathbf{a}_{n}^{\top}\mathbf{b}_{2} & \cdots & \mathbf{a}_{n}^{\top}\mathbf{b}_{m}
\end{array}\right]
$$

可以将矩阵-矩阵乘法 $\mathbf{A}\mathbf{B}$ 看作简单地执行 $m$ 次矩阵-向量积，并将结果拼接在一起，形成一个 $n \times m$ 矩阵；

------

范数（norm）：
- 向量的范数表示一个向量有多大，这里考虑的大小（size）概率不涉及维度，而是分量的大小。范数是线性代数中最有用的一些运算符；
- 向量范数：将向量映射到标量的函数 $f$。
    - 给定任意向量 $\mathbf{x}$，向量范数要满足一些性质：
        1. 如果按常数因子 $\alpha$ 缩放向量的所有元素，其范数也会按相同常数因子的绝对值缩放：$f(\alpha\mathbf{x})=|\alpha|f(\mathbf{x})$；
        2. 三角不等式：$f(\mathbf{x} + \mathbf{y}) \leq f(\mathbf{x}) + f(\mathbf{y})$；
        3. 范数必须是非负的：$f(\mathbf{x}) \geq 0$；（这是有道理的，因为在大多数情况下，任何东西的最小大小都是 $0$）
        4. 范数最小为 $0$，当且仅当向量全由 $0$ 组成：$\forall i, {[\mathbf{x}]}_{i} = 0 \Leftrightarrow f(\mathbf{x})=0$；
- $L_{2}$ 范数：
    - 假设 $n$ 维向量 $\mathbf{x}$ 中的元素是 $x_1, x_2, \dots, x_n$，其 $L_{2}$ 范数是向量元素平方和的平方根：${\parallel \mathbf{x} \parallel}_{2}=\sqrt{\sum\limits_{i=1}^{n} x_{i}^{2}}$；
    - 其中 $L_{2}$ 范数中常常省略下标 $2$，即 ${\parallel \mathbf{x} \parallel}$ 等同于 ${\parallel \mathbf{x} \parallel}_{2}$；
    - 事实上，欧几里得距离是一个 $L_{2}$ 范数；
- $L_{1}$ 范数：
    - 深度学习中更经常地使用 $L_{2}$ 范数的平方，也会经常遇到 $L_{1}$ 范数，它表示为向量元素的绝对值之和：${\parallel \mathbf{x} \parallel}_{1}=\sum\limits_{i=1}^{n}|x_i|$；
    - 与 $L_{2}$ 范数相比，$L_1$ 范数受异常值的影响较小；
- $L_{p}$ 范数：
    - $L_{2}$范数 和 $L_{1}$范数 都是更一般的 $L_{p}$范数 的特例：${\parallel \mathbf{x} \parallel}_{p}={(\sum\limits_{i=1}^{n} {|x_i|}^{p})}^{1/p}$；
- 弗罗贝尼乌斯范数（Frobenius 范数，Frobenius norm）：
    - 矩阵 $\mathbf{X} \in \mathbb{R}^{m \times n}$ 的 Frobenius 范数是矩阵元素平方和的平方根：${\parallel \mathbf{X} \parallel}_{F}=\sqrt{\sum\limits_{i=1}^{m} \sum\limits_{j=1}^{n} x_{ij}^{2}}$；
    - Frobenius 范数满足向量范数的所有性质，其就像是矩阵形向量的 $L_{2}$范数；

**范数和目标**：
- 深度学习中，通常试图解决优化问题：最大化分配给观测数据的概率；最小化预测和真实观测之间的距离；
- 用向量表示对象（如单词、产品等），以便最小化相似项目之间的距离，最大化不同项目之间的距离；
- 目标，或许是深度学习算法最重要的组成部分（除开数据），通常被表达为范数；

------

## 微积分






## 其它

- $f: \mathbb{R} \rightarrow \mathbb{R}$：一元标量运算符（直接收一个输入）。意味着该函数从任何实数（$\mathbb{R}$）映射到另一个实数；
- $f: \mathbb{R}, \mathbb{R} \rightarrow \mathbb{R}$：二元标量运算符。意味着该函数接收两个输入，并产生一个输出；
- $F: \mathbb{R}^d, \mathbb{R}^d \rightarrow \mathbb{R}^d$：按元素向量运算符。给定向量 $\mathbf{u}$ 和 $\mathbf{v}$ 以及二元运算符号 $f$，可构建向量 $\mathbf{c} = F(\mathbf{u}, \mathbf{v})$，具体计算方法为 $c_i \leftarrow f(u_i, v_i)$，其中 $c_i$、$u_i$ 和 $v_i$ 分别是向量 $\mathbf{c}$、$\mathbf{u}$ 和 $\mathbf{v}$ 中的元素；









