# v1
------

> **更新日志**：
> - *v1_fix1*：
>   1. 适配了设备选择逻辑（GPU/CPU）；
>   2. 提交前使用完整数据集（训练集 + 测试集）进行训练；
>   3. 增大 epoch_nums（人工观察训练集 loss 进行选择，避免过拟合）；

**基本信息**：
- 数据集加载与划分：简单划分 $20\%$ 测试集，$80\%$ 训练集。无其它技巧；
- 模型架构：MLP（784-ReLU-64-ReLU-10）；
- 损失函数：MCE（平均交叉熵损失）；
- 优化器：SGD（随机梯度下降）；
- 训练细节：固定训练超参数、固定轮数。无任何技巧；

**工程实现中的错误教训**：
1. *数据预处理*：注意数据的均一化等预处理。犯错：未均一化导致梯度爆炸；
2. *数据类型对齐*：注意数据和模型权重类型对齐。犯错：数据类型和权重类型不匹配报错；

**疑问**：
1. 机器学习比赛中给出的 test_data 是无标签的，那使用半监督学习利用这部分数据是否算数据泄露？
2. 通常划分带标签数据集为训练集和测试集，并在训练过程中每个 epoch 输出测试集上效果。但是最终交付的时候训练模型要使用完整的数据集（训练集 + 测试集），此时训练的超参数怎么设定呢？此时用于观测的测试集又该怎么设定呢？
3. 工程实现中怎么判断模型训练出现了过拟合？（只要测试集 loss 呈现下降趋势就没有过拟合，呈现上升趋势时就是开始过拟合了吗？）







